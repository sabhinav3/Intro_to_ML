{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabhinav3/Intro_to_ML/blob/main/abhi_hw6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I9U6_EDUuLMl"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "boston = fetch_california_housing(as_frame=True)\n",
        "# Load the Boston Housing dataset\n",
        "# boston = fetch_openml(name='boston', version=2)\n",
        "X, y = boston.data, boston.target\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naxbcNtIucb7",
        "outputId": "12f32d60-2e1c-43c4-b842-e299c57e720a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "516/516 [==============================] - 5s 6ms/step - loss: 1.8734 - val_loss: 0.6974\n",
            "Epoch 2/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.6174 - val_loss: 0.5449\n",
            "Epoch 3/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.4933 - val_loss: 0.4710\n",
            "Epoch 4/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.4390 - val_loss: 0.4345\n",
            "Epoch 5/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.4129 - val_loss: 0.4182\n",
            "Epoch 6/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3989 - val_loss: 0.4075\n",
            "Epoch 7/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3899 - val_loss: 0.4005\n",
            "Epoch 8/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3838 - val_loss: 0.3937\n",
            "Epoch 9/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3782 - val_loss: 0.3887\n",
            "Epoch 10/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3727 - val_loss: 0.3840\n",
            "Epoch 11/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3704 - val_loss: 0.3790\n",
            "Epoch 12/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.3756\n",
            "Epoch 13/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3730\n",
            "Epoch 14/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3796 - val_loss: 0.3711\n",
            "Epoch 15/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.3688\n",
            "Epoch 16/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3494 - val_loss: 0.3631\n",
            "Epoch 17/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3476 - val_loss: 0.3661\n",
            "Epoch 18/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.3432 - val_loss: 0.3669\n",
            "Epoch 19/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.3632\n",
            "Epoch 20/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3585\n",
            "Epoch 21/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3362 - val_loss: 0.3576\n",
            "Epoch 22/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3339 - val_loss: 0.3493\n",
            "Epoch 23/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3471\n",
            "Epoch 24/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3289 - val_loss: 0.3419\n",
            "Epoch 25/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3281 - val_loss: 0.3432\n",
            "Epoch 26/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3258 - val_loss: 0.3358\n",
            "Epoch 27/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3247 - val_loss: 0.3374\n",
            "Epoch 28/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.3304 - val_loss: 0.3389\n",
            "Epoch 29/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3210 - val_loss: 0.3396\n",
            "Epoch 30/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3212 - val_loss: 0.3336\n",
            "Epoch 31/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3201 - val_loss: 0.3386\n",
            "Epoch 32/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3231 - val_loss: 0.3320\n",
            "Epoch 33/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3173 - val_loss: 0.3336\n",
            "Epoch 34/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3161 - val_loss: 0.3388\n",
            "Epoch 35/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3204 - val_loss: 0.3360\n",
            "Epoch 36/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3180 - val_loss: 0.3335\n",
            "Epoch 37/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3200 - val_loss: 0.3286\n",
            "Epoch 38/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3125 - val_loss: 0.3264\n",
            "Epoch 39/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3200 - val_loss: 0.3286\n",
            "Epoch 40/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3116 - val_loss: 0.3319\n",
            "Epoch 41/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3122 - val_loss: 0.3320\n",
            "Epoch 42/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3157 - val_loss: 0.3256\n",
            "Epoch 43/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3116 - val_loss: 0.3285\n",
            "Epoch 44/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3113 - val_loss: 0.3286\n",
            "Epoch 45/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3331 - val_loss: 0.3255\n",
            "Epoch 46/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3085 - val_loss: 0.3256\n",
            "Epoch 47/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3071 - val_loss: 0.3303\n",
            "Epoch 48/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.3076 - val_loss: 0.3221\n",
            "Epoch 49/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.3095 - val_loss: 0.3407\n",
            "Epoch 50/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3090 - val_loss: 0.3249\n",
            "Epoch 51/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3076 - val_loss: 0.3243\n",
            "Epoch 52/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3057 - val_loss: 0.3272\n",
            "Epoch 53/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3130 - val_loss: 0.3235\n",
            "Epoch 54/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3066 - val_loss: 0.3196\n",
            "Epoch 55/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3042 - val_loss: 0.3217\n",
            "Epoch 56/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3061 - val_loss: 0.3193\n",
            "Epoch 57/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3029 - val_loss: 0.3219\n",
            "Epoch 58/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3075 - val_loss: 0.3193\n",
            "Epoch 59/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.3067 - val_loss: 0.3199\n",
            "Epoch 60/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.3081 - val_loss: 0.3160\n",
            "Epoch 61/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3013 - val_loss: 0.3154\n",
            "Epoch 62/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3010 - val_loss: 0.3248\n",
            "Epoch 63/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3016 - val_loss: 0.3159\n",
            "Epoch 64/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3001 - val_loss: 0.3219\n",
            "Epoch 65/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3027 - val_loss: 0.3144\n",
            "Epoch 66/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.3112 - val_loss: 0.3176\n",
            "Epoch 67/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2989 - val_loss: 0.3231\n",
            "Epoch 68/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2989 - val_loss: 0.3132\n",
            "Epoch 69/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2990 - val_loss: 0.3146\n",
            "Epoch 70/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3053 - val_loss: 0.3146\n",
            "Epoch 71/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3039 - val_loss: 0.3126\n",
            "Epoch 72/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3023 - val_loss: 0.3137\n",
            "Epoch 73/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2971 - val_loss: 0.3182\n",
            "Epoch 74/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2977 - val_loss: 0.3163\n",
            "Epoch 75/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3025 - val_loss: 0.3128\n",
            "Epoch 76/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3009 - val_loss: 0.3172\n",
            "Epoch 77/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2961 - val_loss: 0.3147\n",
            "Epoch 78/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2966 - val_loss: 0.3160\n",
            "Epoch 79/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2964 - val_loss: 0.3139\n",
            "Epoch 80/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2952 - val_loss: 0.3145\n",
            "Epoch 81/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.3048 - val_loss: 0.3111\n",
            "Epoch 82/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2944 - val_loss: 0.3118\n",
            "Epoch 83/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2963 - val_loss: 0.3147\n",
            "Epoch 84/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3066 - val_loss: 0.3103\n",
            "Epoch 85/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3036 - val_loss: 0.3099\n",
            "Epoch 86/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2944 - val_loss: 0.3095\n",
            "Epoch 87/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2967 - val_loss: 0.3080\n",
            "Epoch 88/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2939 - val_loss: 0.3087\n",
            "Epoch 89/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2949 - val_loss: 0.3102\n",
            "Epoch 90/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2934 - val_loss: 0.3163\n",
            "Epoch 91/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2921 - val_loss: 0.3105\n",
            "Epoch 92/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2964 - val_loss: 0.3101\n",
            "Epoch 93/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3399 - val_loss: 0.3141\n",
            "Epoch 94/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2939 - val_loss: 0.3122\n",
            "Epoch 95/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2922 - val_loss: 0.3063\n",
            "Epoch 96/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2925 - val_loss: 0.3099\n",
            "Epoch 97/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2910 - val_loss: 0.3107\n",
            "Epoch 98/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2922 - val_loss: 0.3087\n",
            "Epoch 99/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2941 - val_loss: 0.3093\n",
            "Epoch 100/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2919 - val_loss: 0.3115\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2912\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.3115\n",
            "Training Loss: 0.29118478298187256\n",
            "Validation Loss: 0.31145355105400085\n"
          ]
        }
      ],
      "source": [
        "# Build the neural network model\n",
        "model1 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(1)  # Output layer with one neuron for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model1.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model\n",
        "train_loss1 = model1.evaluate(X_train, y_train)\n",
        "val_loss1 = model1.evaluate(X_val, y_val)\n",
        "\n",
        "print(f'Training Loss: {train_loss1}')\n",
        "print(f'Validation Loss: {val_loss1}')\n",
        "\n",
        "# Compare with linear regression results\n",
        
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results of Homework 5 Linear Model:\n",
        "\n",
        "Training Loss: 1350008176640.0000, Validation Loss: 2292721647616.0000\n",
        "\n",
        "Current results are better."
      ],
      "metadata": {
        "id": "ShdFR9YWLF3p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMH9MxV6pOv1",
        "outputId": "d396e9aa-4abc-42aa-adda-bf6af35db06e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "516/516 [==============================] - 3s 3ms/step - loss: 1.1199 - val_loss: 0.4791\n",
            "Epoch 2/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.4231 - val_loss: 0.3948\n",
            "Epoch 3/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3797 - val_loss: 0.3688\n",
            "Epoch 4/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.3484\n",
            "Epoch 5/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3399 - val_loss: 0.3425\n",
            "Epoch 6/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3313 - val_loss: 0.3376\n",
            "Epoch 7/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.3133 - val_loss: 0.3285\n",
            "Epoch 8/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.3089 - val_loss: 0.3100\n",
            "Epoch 9/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.3035 - val_loss: 0.3047\n",
            "Epoch 10/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3313\n",
            "Epoch 11/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2978 - val_loss: 0.3024\n",
            "Epoch 12/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2914 - val_loss: 0.3030\n",
            "Epoch 13/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2897 - val_loss: 0.3075\n",
            "Epoch 14/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2867 - val_loss: 0.2936\n",
            "Epoch 15/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2864 - val_loss: 0.2941\n",
            "Epoch 16/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2834 - val_loss: 0.2881\n",
            "Epoch 17/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2815 - val_loss: 0.2962\n",
            "Epoch 18/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2845 - val_loss: 0.2971\n",
            "Epoch 19/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2742 - val_loss: 0.2907\n",
            "Epoch 20/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2745 - val_loss: 0.2913\n",
            "Epoch 21/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2748 - val_loss: 0.2963\n",
            "Epoch 22/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2725 - val_loss: 0.2843\n",
            "Epoch 23/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2720 - val_loss: 0.2954\n",
            "Epoch 24/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2682 - val_loss: 0.2802\n",
            "Epoch 25/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2663 - val_loss: 0.2926\n",
            "Epoch 26/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2639 - val_loss: 0.2861\n",
            "Epoch 27/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2655 - val_loss: 0.2751\n",
            "Epoch 28/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2625 - val_loss: 0.2795\n",
            "Epoch 29/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2634 - val_loss: 0.2752\n",
            "Epoch 30/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2585 - val_loss: 0.2915\n",
            "Epoch 31/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2593 - val_loss: 0.2791\n",
            "Epoch 32/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2563 - val_loss: 0.2789\n",
            "Epoch 33/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2570 - val_loss: 0.2956\n",
            "Epoch 34/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2606 - val_loss: 0.2765\n",
            "Epoch 35/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2546 - val_loss: 0.2744\n",
            "Epoch 36/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2535 - val_loss: 0.2758\n",
            "Epoch 37/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2522 - val_loss: 0.2699\n",
            "Epoch 38/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2514 - val_loss: 0.2833\n",
            "Epoch 39/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2496 - val_loss: 0.2728\n",
            "Epoch 40/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2481 - val_loss: 0.2835\n",
            "Epoch 41/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2530 - val_loss: 0.2942\n",
            "Epoch 42/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2480 - val_loss: 0.2811\n",
            "Epoch 43/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2469 - val_loss: 0.2768\n",
            "Epoch 44/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2461 - val_loss: 0.2665\n",
            "Epoch 45/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2439 - val_loss: 0.2696\n",
            "Epoch 46/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2468 - val_loss: 0.2780\n",
            "Epoch 47/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2446 - val_loss: 0.2823\n",
            "Epoch 48/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2424 - val_loss: 0.2701\n",
            "Epoch 49/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2435 - val_loss: 0.2695\n",
            "Epoch 50/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2423 - val_loss: 0.2846\n",
            "Epoch 51/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2419 - val_loss: 0.2768\n",
            "Epoch 52/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2398 - val_loss: 0.2669\n",
            "Epoch 53/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2399 - val_loss: 0.2744\n",
            "Epoch 54/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2387 - val_loss: 0.2775\n",
            "Epoch 55/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2493 - val_loss: 0.2742\n",
            "Epoch 56/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2396 - val_loss: 0.2667\n",
            "Epoch 57/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2355 - val_loss: 0.2706\n",
            "Epoch 58/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2356 - val_loss: 0.2699\n",
            "Epoch 59/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2370 - val_loss: 0.2734\n",
            "Epoch 60/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2383 - val_loss: 0.2774\n",
            "Epoch 61/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2362 - val_loss: 0.2785\n",
            "Epoch 62/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2350 - val_loss: 0.2664\n",
            "Epoch 63/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2362 - val_loss: 0.2720\n",
            "Epoch 64/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2346 - val_loss: 0.2680\n",
            "Epoch 65/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2325 - val_loss: 0.2842\n",
            "Epoch 66/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2341 - val_loss: 0.2677\n",
            "Epoch 67/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2315 - val_loss: 0.2710\n",
            "Epoch 68/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2310 - val_loss: 0.2674\n",
            "Epoch 69/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2319 - val_loss: 0.2675\n",
            "Epoch 70/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2311 - val_loss: 0.2651\n",
            "Epoch 71/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2291 - val_loss: 0.2777\n",
            "Epoch 72/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2333 - val_loss: 0.2708\n",
            "Epoch 73/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2309 - val_loss: 0.2682\n",
            "Epoch 74/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2270 - val_loss: 0.2728\n",
            "Epoch 75/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2273 - val_loss: 0.2757\n",
            "Epoch 76/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2285 - val_loss: 0.2670\n",
            "Epoch 77/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2272 - val_loss: 0.2678\n",
            "Epoch 78/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2277 - val_loss: 0.2699\n",
            "Epoch 79/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2269 - val_loss: 0.2684\n",
            "Epoch 80/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2260 - val_loss: 0.2697\n",
            "Epoch 81/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2242 - val_loss: 0.2659\n",
            "Epoch 82/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2234 - val_loss: 0.2652\n",
            "Epoch 83/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2259 - val_loss: 0.2615\n",
            "Epoch 84/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2247 - val_loss: 0.2785\n",
            "Epoch 85/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2237 - val_loss: 0.2726\n",
            "Epoch 86/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2248 - val_loss: 0.2728\n",
            "Epoch 87/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2204 - val_loss: 0.2639\n",
            "Epoch 88/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2210 - val_loss: 0.2642\n",
            "Epoch 89/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2206 - val_loss: 0.2718\n",
            "Epoch 90/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2208 - val_loss: 0.2655\n",
            "Epoch 91/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2206 - val_loss: 0.2717\n",
            "Epoch 92/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2196 - val_loss: 0.2674\n",
            "Epoch 93/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.2194 - val_loss: 0.2634\n",
            "Epoch 94/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2202 - val_loss: 0.2630\n",
            "Epoch 95/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2193 - val_loss: 0.2621\n",
            "Epoch 96/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2182 - val_loss: 0.2648\n",
            "Epoch 97/100\n",
            "516/516 [==============================] - 2s 3ms/step - loss: 0.2189 - val_loss: 0.2671\n",
            "Epoch 98/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2210 - val_loss: 0.2648\n",
            "Epoch 99/100\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2162 - val_loss: 0.2673\n",
            "Epoch 100/100\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.2156 - val_loss: 0.2597\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.2050\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2597\n",
            "Training Loss: 0.20503728091716766\n",
            "Validation Loss: 0.2597484886646271\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 32)                288       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3457 (13.50 KB)\n",
            "Trainable params: 3457 (13.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Build the neural network model with three hidden layers\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)  # Output layer with one neuron for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model\n",
        "train_loss = model.evaluate(X_train, y_train)\n",
        "val_loss = model.evaluate(X_val, y_val)\n",
        "\n",
        "print(f'Training Loss: {train_loss}')\n",
        "print(f'Validation Loss: {val_loss}')\n",
        "\n",
        "# # Compare with linear regression results\n",
        "# linear_reg_model = LinearRegression()\n",
        "# linear_reg_model.fit(X_train, y_train)\n",
        "\n",
        "# # Evaluate linear regression model\n",
        "# y_train_pred = linear_reg_model.predict(X_train)\n",
        "# y_val_pred = linear_reg_model.predict(X_val)\n",
        "\n",
        "# train_loss_linear_reg = mean_squared_error(y_train, y_train_pred)\n",
        "# val_loss_linear_reg = mean_squared_error(y_val, y_val_pred)\n",
        "\n",
        "# print(f'Linear Regression Training Loss: {train_loss_linear_reg}')\n",
        "# print(f'Linear Regression Validation Loss: {val_loss_linear_reg}')\n",
        "\n",
        "# Compare model complexity\n",
        "model.summary()  # Display the summary to see the number of trainable parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results of Homework 5 Linear Model:\n",
        "\n",
        "Training Loss: 1350008176640.0000, Validation Loss: 2292721647616.0000\n",
        "\n",
        "Previous model results:\n",
        "\n",
        "Training Loss: 0.2880136966705322 Validation Loss: 0.3124917149543762\n",
        "\n",
        "Current results are better."
      ],
      "metadata": {
        "id": "r2h3qGFaLL-y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yxNawgBzkLZ"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63p6pYqIzb4q",
        "outputId": "73286f1a-7f5b-4542-c55e-8c0223fa4f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 1.8933 - accuracy: 0.3262 - val_loss: 1.7393 - val_accuracy: 0.3818\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.7030 - accuracy: 0.3904 - val_loss: 1.6407 - val_accuracy: 0.4131\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 1.6343 - accuracy: 0.4163 - val_loss: 1.5785 - val_accuracy: 0.4376\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.5977 - accuracy: 0.4298 - val_loss: 1.6008 - val_accuracy: 0.4263\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.5694 - accuracy: 0.4417 - val_loss: 1.5671 - val_accuracy: 0.4443\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 1.5446 - accuracy: 0.4511 - val_loss: 1.5878 - val_accuracy: 0.4317\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.5272 - accuracy: 0.4574 - val_loss: 1.5788 - val_accuracy: 0.4398\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.5101 - accuracy: 0.4629 - val_loss: 1.5314 - val_accuracy: 0.4547\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.4965 - accuracy: 0.4705 - val_loss: 1.5202 - val_accuracy: 0.4586\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 1.4838 - accuracy: 0.4749 - val_loss: 1.5419 - val_accuracy: 0.4535\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.5419 - accuracy: 0.4535\n",
            "Training Time: 444.71009707450867 seconds\n",
            "Training Loss: 1.4837892055511475\n",
            "Test Accuracy: 0.45350000262260437\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "# Build the neural network model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(32, 32, 3)))  # Flatten the image\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "# Print results\n",
        "print(f'Training Time: {training_time} seconds')\n",
        "print(f'Training Loss: {history.history[\"loss\"][-1]}')\n",
        "print(f'Test Accuracy: {test_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puCIdpANzmU4",
        "outputId": "14d3ed24-9e1d-40a0-a66c-3b53907d9f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1563/1563 [==============================] - 45s 28ms/step - loss: 1.8596 - accuracy: 0.3239 - val_loss: 1.7136 - val_accuracy: 0.3868\n",
            "Epoch 2/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.6795 - accuracy: 0.3981 - val_loss: 1.6365 - val_accuracy: 0.4106\n",
            "Epoch 3/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.6003 - accuracy: 0.4262 - val_loss: 1.5913 - val_accuracy: 0.4307\n",
            "Epoch 4/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.5451 - accuracy: 0.4481 - val_loss: 1.5069 - val_accuracy: 0.4589\n",
            "Epoch 5/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.5030 - accuracy: 0.4629 - val_loss: 1.4934 - val_accuracy: 0.4692\n",
            "Epoch 6/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4671 - accuracy: 0.4726 - val_loss: 1.5496 - val_accuracy: 0.4496\n",
            "Epoch 7/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.4461 - accuracy: 0.4789 - val_loss: 1.4565 - val_accuracy: 0.4820\n",
            "Epoch 8/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4128 - accuracy: 0.4932 - val_loss: 1.4828 - val_accuracy: 0.4674\n",
            "Epoch 9/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3958 - accuracy: 0.4960 - val_loss: 1.4588 - val_accuracy: 0.4870\n",
            "Epoch 10/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3727 - accuracy: 0.5075 - val_loss: 1.4744 - val_accuracy: 0.4727\n",
            "Epoch 11/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3505 - accuracy: 0.5163 - val_loss: 1.4318 - val_accuracy: 0.4954\n",
            "Epoch 12/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.3338 - accuracy: 0.5222 - val_loss: 1.4391 - val_accuracy: 0.4933\n",
            "Epoch 13/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.3187 - accuracy: 0.5266 - val_loss: 1.4556 - val_accuracy: 0.4871\n",
            "Epoch 14/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3021 - accuracy: 0.5329 - val_loss: 1.4194 - val_accuracy: 0.4998\n",
            "Epoch 15/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.2857 - accuracy: 0.5389 - val_loss: 1.4609 - val_accuracy: 0.4933\n",
            "Epoch 16/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.2726 - accuracy: 0.5420 - val_loss: 1.4380 - val_accuracy: 0.5024\n",
            "Epoch 17/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 1.2569 - accuracy: 0.5495 - val_loss: 1.4563 - val_accuracy: 0.4930\n",
            "Epoch 18/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.2444 - accuracy: 0.5530 - val_loss: 1.4220 - val_accuracy: 0.5032\n",
            "Epoch 19/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.2255 - accuracy: 0.5602 - val_loss: 1.4282 - val_accuracy: 0.5062\n",
            "Epoch 20/300\n",
            "1563/1563 [==============================] - 45s 28ms/step - loss: 1.2205 - accuracy: 0.5620 - val_loss: 1.4481 - val_accuracy: 0.4991\n",
            "Epoch 21/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.2002 - accuracy: 0.5710 - val_loss: 1.4609 - val_accuracy: 0.4997\n",
            "Epoch 22/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.1893 - accuracy: 0.5721 - val_loss: 1.4836 - val_accuracy: 0.4901\n",
            "Epoch 23/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.1744 - accuracy: 0.5767 - val_loss: 1.4827 - val_accuracy: 0.4941\n",
            "Epoch 24/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.1686 - accuracy: 0.5788 - val_loss: 1.4775 - val_accuracy: 0.4993\n",
            "Epoch 25/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.1515 - accuracy: 0.5851 - val_loss: 1.5422 - val_accuracy: 0.4777\n",
            "Epoch 26/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.1448 - accuracy: 0.5884 - val_loss: 1.5144 - val_accuracy: 0.4998\n",
            "Epoch 27/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 1.1315 - accuracy: 0.5916 - val_loss: 1.5076 - val_accuracy: 0.4926\n",
            "Epoch 28/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 1.1212 - accuracy: 0.5967 - val_loss: 1.5398 - val_accuracy: 0.4829\n",
            "Epoch 29/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.1160 - accuracy: 0.5984 - val_loss: 1.5394 - val_accuracy: 0.4916\n",
            "Epoch 30/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.1011 - accuracy: 0.6042 - val_loss: 1.5140 - val_accuracy: 0.4986\n",
            "Epoch 31/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0903 - accuracy: 0.6056 - val_loss: 1.5391 - val_accuracy: 0.5005\n",
            "Epoch 32/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0828 - accuracy: 0.6124 - val_loss: 1.5377 - val_accuracy: 0.4971\n",
            "Epoch 33/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0665 - accuracy: 0.6146 - val_loss: 1.5554 - val_accuracy: 0.4972\n",
            "Epoch 34/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0619 - accuracy: 0.6166 - val_loss: 1.6139 - val_accuracy: 0.4909\n",
            "Epoch 35/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0563 - accuracy: 0.6213 - val_loss: 1.5650 - val_accuracy: 0.4989\n",
            "Epoch 36/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0422 - accuracy: 0.6232 - val_loss: 1.5825 - val_accuracy: 0.4851\n",
            "Epoch 37/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0337 - accuracy: 0.6267 - val_loss: 1.6307 - val_accuracy: 0.4929\n",
            "Epoch 38/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0278 - accuracy: 0.6291 - val_loss: 1.6222 - val_accuracy: 0.4986\n",
            "Epoch 39/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0136 - accuracy: 0.6326 - val_loss: 1.6394 - val_accuracy: 0.4873\n",
            "Epoch 40/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0033 - accuracy: 0.6373 - val_loss: 1.6528 - val_accuracy: 0.4940\n",
            "Epoch 41/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 1.0034 - accuracy: 0.6368 - val_loss: 1.6584 - val_accuracy: 0.4921\n",
            "Epoch 42/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.9943 - accuracy: 0.6380 - val_loss: 1.6867 - val_accuracy: 0.4785\n",
            "Epoch 43/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.9859 - accuracy: 0.6427 - val_loss: 1.7099 - val_accuracy: 0.4820\n",
            "Epoch 44/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.9752 - accuracy: 0.6472 - val_loss: 1.7429 - val_accuracy: 0.4793\n",
            "Epoch 45/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.9774 - accuracy: 0.6471 - val_loss: 1.7674 - val_accuracy: 0.4829\n",
            "Epoch 46/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.9695 - accuracy: 0.6484 - val_loss: 1.7238 - val_accuracy: 0.4936\n",
            "Epoch 47/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.9561 - accuracy: 0.6548 - val_loss: 1.7505 - val_accuracy: 0.4870\n",
            "Epoch 48/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.9525 - accuracy: 0.6541 - val_loss: 1.8176 - val_accuracy: 0.4782\n",
            "Epoch 49/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.9464 - accuracy: 0.6568 - val_loss: 1.8085 - val_accuracy: 0.4849\n",
            "Epoch 50/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.9405 - accuracy: 0.6581 - val_loss: 1.8344 - val_accuracy: 0.4747\n",
            "Epoch 51/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.9350 - accuracy: 0.6624 - val_loss: 1.8594 - val_accuracy: 0.4772\n",
            "Epoch 52/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.9279 - accuracy: 0.6641 - val_loss: 1.7745 - val_accuracy: 0.4895\n",
            "Epoch 53/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.9237 - accuracy: 0.6660 - val_loss: 1.8328 - val_accuracy: 0.4827\n",
            "Epoch 54/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.9180 - accuracy: 0.6659 - val_loss: 1.8863 - val_accuracy: 0.4825\n",
            "Epoch 55/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.9086 - accuracy: 0.6699 - val_loss: 1.8977 - val_accuracy: 0.4839\n",
            "Epoch 56/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.9047 - accuracy: 0.6715 - val_loss: 1.8371 - val_accuracy: 0.4826\n",
            "Epoch 57/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8905 - accuracy: 0.6756 - val_loss: 1.8713 - val_accuracy: 0.4865\n",
            "Epoch 58/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.8877 - accuracy: 0.6776 - val_loss: 1.8714 - val_accuracy: 0.4850\n",
            "Epoch 59/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.8804 - accuracy: 0.6795 - val_loss: 1.9290 - val_accuracy: 0.4793\n",
            "Epoch 60/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.8797 - accuracy: 0.6812 - val_loss: 1.9030 - val_accuracy: 0.4839\n",
            "Epoch 61/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8764 - accuracy: 0.6809 - val_loss: 1.8663 - val_accuracy: 0.4937\n",
            "Epoch 62/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8736 - accuracy: 0.6839 - val_loss: 1.9073 - val_accuracy: 0.4840\n",
            "Epoch 63/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.8646 - accuracy: 0.6853 - val_loss: 1.9276 - val_accuracy: 0.4864\n",
            "Epoch 64/300\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 0.8583 - accuracy: 0.6889 - val_loss: 2.0178 - val_accuracy: 0.4835\n",
            "Epoch 65/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8620 - accuracy: 0.6878 - val_loss: 2.0159 - val_accuracy: 0.4798\n",
            "Epoch 66/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8463 - accuracy: 0.6912 - val_loss: 1.9291 - val_accuracy: 0.4858\n",
            "Epoch 67/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8554 - accuracy: 0.6910 - val_loss: 1.9844 - val_accuracy: 0.4850\n",
            "Epoch 68/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.8350 - accuracy: 0.6969 - val_loss: 2.0116 - val_accuracy: 0.4788\n",
            "Epoch 69/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8358 - accuracy: 0.6984 - val_loss: 1.9995 - val_accuracy: 0.4747\n",
            "Epoch 70/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.8406 - accuracy: 0.6938 - val_loss: 2.0910 - val_accuracy: 0.4720\n",
            "Epoch 71/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8246 - accuracy: 0.7010 - val_loss: 2.0328 - val_accuracy: 0.4802\n",
            "Epoch 72/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8243 - accuracy: 0.7013 - val_loss: 2.0134 - val_accuracy: 0.4824\n",
            "Epoch 73/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8264 - accuracy: 0.7014 - val_loss: 2.0411 - val_accuracy: 0.4794\n",
            "Epoch 74/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8141 - accuracy: 0.7049 - val_loss: 2.1598 - val_accuracy: 0.4749\n",
            "Epoch 75/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8088 - accuracy: 0.7061 - val_loss: 2.1233 - val_accuracy: 0.4721\n",
            "Epoch 76/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8072 - accuracy: 0.7046 - val_loss: 2.1765 - val_accuracy: 0.4761\n",
            "Epoch 77/300\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 0.7977 - accuracy: 0.7106 - val_loss: 2.1556 - val_accuracy: 0.4757\n",
            "Epoch 78/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.7912 - accuracy: 0.7118 - val_loss: 2.1648 - val_accuracy: 0.4746\n",
            "Epoch 79/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8000 - accuracy: 0.7089 - val_loss: 2.1987 - val_accuracy: 0.4755\n",
            "Epoch 80/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.7922 - accuracy: 0.7130 - val_loss: 2.1302 - val_accuracy: 0.4698\n",
            "Epoch 81/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.7848 - accuracy: 0.7143 - val_loss: 2.1896 - val_accuracy: 0.4764\n",
            "Epoch 82/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7809 - accuracy: 0.7160 - val_loss: 2.2630 - val_accuracy: 0.4729\n",
            "Epoch 83/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7820 - accuracy: 0.7178 - val_loss: 2.1899 - val_accuracy: 0.4766\n",
            "Epoch 84/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7725 - accuracy: 0.7185 - val_loss: 2.2370 - val_accuracy: 0.4732\n",
            "Epoch 85/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7758 - accuracy: 0.7185 - val_loss: 2.2819 - val_accuracy: 0.4697\n",
            "Epoch 86/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7748 - accuracy: 0.7193 - val_loss: 2.2399 - val_accuracy: 0.4773\n",
            "Epoch 87/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7687 - accuracy: 0.7207 - val_loss: 2.2246 - val_accuracy: 0.4745\n",
            "Epoch 88/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7660 - accuracy: 0.7195 - val_loss: 2.2719 - val_accuracy: 0.4766\n",
            "Epoch 89/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7636 - accuracy: 0.7219 - val_loss: 2.3640 - val_accuracy: 0.4722\n",
            "Epoch 90/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7557 - accuracy: 0.7264 - val_loss: 2.2733 - val_accuracy: 0.4704\n",
            "Epoch 91/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7594 - accuracy: 0.7263 - val_loss: 2.3319 - val_accuracy: 0.4787\n",
            "Epoch 92/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7514 - accuracy: 0.7278 - val_loss: 2.2733 - val_accuracy: 0.4783\n",
            "Epoch 93/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7542 - accuracy: 0.7276 - val_loss: 2.4028 - val_accuracy: 0.4781\n",
            "Epoch 94/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7495 - accuracy: 0.7266 - val_loss: 2.4142 - val_accuracy: 0.4720\n",
            "Epoch 95/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7412 - accuracy: 0.7302 - val_loss: 2.4344 - val_accuracy: 0.4723\n",
            "Epoch 96/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7381 - accuracy: 0.7334 - val_loss: 2.4221 - val_accuracy: 0.4738\n",
            "Epoch 97/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7351 - accuracy: 0.7344 - val_loss: 2.3285 - val_accuracy: 0.4729\n",
            "Epoch 98/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7365 - accuracy: 0.7313 - val_loss: 2.5706 - val_accuracy: 0.4611\n",
            "Epoch 99/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7339 - accuracy: 0.7334 - val_loss: 2.3399 - val_accuracy: 0.4786\n",
            "Epoch 100/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7294 - accuracy: 0.7371 - val_loss: 2.4547 - val_accuracy: 0.4732\n",
            "Epoch 101/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7188 - accuracy: 0.7384 - val_loss: 2.5165 - val_accuracy: 0.4718\n",
            "Epoch 102/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7260 - accuracy: 0.7359 - val_loss: 2.4784 - val_accuracy: 0.4703\n",
            "Epoch 103/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7130 - accuracy: 0.7423 - val_loss: 2.5404 - val_accuracy: 0.4692\n",
            "Epoch 104/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7214 - accuracy: 0.7388 - val_loss: 2.4959 - val_accuracy: 0.4756\n",
            "Epoch 105/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7137 - accuracy: 0.7405 - val_loss: 2.6949 - val_accuracy: 0.4637\n",
            "Epoch 106/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7227 - accuracy: 0.7398 - val_loss: 2.5646 - val_accuracy: 0.4711\n",
            "Epoch 107/300\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 0.7013 - accuracy: 0.7441 - val_loss: 2.5507 - val_accuracy: 0.4717\n",
            "Epoch 108/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7090 - accuracy: 0.7421 - val_loss: 2.6675 - val_accuracy: 0.4645\n",
            "Epoch 109/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6942 - accuracy: 0.7484 - val_loss: 2.5656 - val_accuracy: 0.4769\n",
            "Epoch 110/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7022 - accuracy: 0.7455 - val_loss: 2.5855 - val_accuracy: 0.4656\n",
            "Epoch 111/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7063 - accuracy: 0.7429 - val_loss: 2.5776 - val_accuracy: 0.4659\n",
            "Epoch 112/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6895 - accuracy: 0.7489 - val_loss: 2.6049 - val_accuracy: 0.4712\n",
            "Epoch 113/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6892 - accuracy: 0.7508 - val_loss: 2.6279 - val_accuracy: 0.4672\n",
            "Epoch 114/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6991 - accuracy: 0.7463 - val_loss: 2.6604 - val_accuracy: 0.4643\n",
            "Epoch 115/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6976 - accuracy: 0.7474 - val_loss: 2.6083 - val_accuracy: 0.4725\n",
            "Epoch 116/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6912 - accuracy: 0.7516 - val_loss: 2.7665 - val_accuracy: 0.4718\n",
            "Epoch 117/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6830 - accuracy: 0.7526 - val_loss: 2.7586 - val_accuracy: 0.4652\n",
            "Epoch 118/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6769 - accuracy: 0.7545 - val_loss: 2.7190 - val_accuracy: 0.4700\n",
            "Epoch 119/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6889 - accuracy: 0.7489 - val_loss: 2.8155 - val_accuracy: 0.4682\n",
            "Epoch 120/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6827 - accuracy: 0.7511 - val_loss: 2.6868 - val_accuracy: 0.4726\n",
            "Epoch 121/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6760 - accuracy: 0.7542 - val_loss: 2.8217 - val_accuracy: 0.4670\n",
            "Epoch 122/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6714 - accuracy: 0.7570 - val_loss: 2.7898 - val_accuracy: 0.4639\n",
            "Epoch 123/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6792 - accuracy: 0.7555 - val_loss: 2.9983 - val_accuracy: 0.4613\n",
            "Epoch 124/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6610 - accuracy: 0.7611 - val_loss: 2.8795 - val_accuracy: 0.4643\n",
            "Epoch 125/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6764 - accuracy: 0.7564 - val_loss: 2.8128 - val_accuracy: 0.4620\n",
            "Epoch 126/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6688 - accuracy: 0.7557 - val_loss: 2.8935 - val_accuracy: 0.4716\n",
            "Epoch 127/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6722 - accuracy: 0.7566 - val_loss: 2.7944 - val_accuracy: 0.4659\n",
            "Epoch 128/300\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 0.6511 - accuracy: 0.7630 - val_loss: 2.8302 - val_accuracy: 0.4669\n",
            "Epoch 129/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6751 - accuracy: 0.7561 - val_loss: 2.7266 - val_accuracy: 0.4759\n",
            "Epoch 130/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6490 - accuracy: 0.7659 - val_loss: 2.8689 - val_accuracy: 0.4674\n",
            "Epoch 131/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6580 - accuracy: 0.7612 - val_loss: 2.9145 - val_accuracy: 0.4597\n",
            "Epoch 132/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6643 - accuracy: 0.7606 - val_loss: 2.8932 - val_accuracy: 0.4574\n",
            "Epoch 133/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6492 - accuracy: 0.7644 - val_loss: 2.8450 - val_accuracy: 0.4711\n",
            "Epoch 134/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6548 - accuracy: 0.7620 - val_loss: 2.9029 - val_accuracy: 0.4682\n",
            "Epoch 135/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6552 - accuracy: 0.7628 - val_loss: 3.0638 - val_accuracy: 0.4605\n",
            "Epoch 136/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6528 - accuracy: 0.7632 - val_loss: 3.0215 - val_accuracy: 0.4573\n",
            "Epoch 137/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6472 - accuracy: 0.7657 - val_loss: 2.8750 - val_accuracy: 0.4700\n",
            "Epoch 138/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6428 - accuracy: 0.7665 - val_loss: 3.1594 - val_accuracy: 0.4560\n",
            "Epoch 139/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6458 - accuracy: 0.7658 - val_loss: 3.1165 - val_accuracy: 0.4650\n",
            "Epoch 140/300\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 0.6416 - accuracy: 0.7685 - val_loss: 2.9980 - val_accuracy: 0.4719\n",
            "Epoch 141/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6523 - accuracy: 0.7643 - val_loss: 2.8917 - val_accuracy: 0.4750\n",
            "Epoch 142/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6367 - accuracy: 0.7699 - val_loss: 2.9188 - val_accuracy: 0.4687\n",
            "Epoch 143/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.6371 - accuracy: 0.7690 - val_loss: 2.9846 - val_accuracy: 0.4586\n",
            "Epoch 144/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6305 - accuracy: 0.7693 - val_loss: 3.0288 - val_accuracy: 0.4629\n",
            "Epoch 145/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6303 - accuracy: 0.7702 - val_loss: 3.1664 - val_accuracy: 0.4639\n",
            "Epoch 146/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6254 - accuracy: 0.7730 - val_loss: 3.0374 - val_accuracy: 0.4682\n",
            "Epoch 147/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6286 - accuracy: 0.7730 - val_loss: 3.0198 - val_accuracy: 0.4625\n",
            "Epoch 148/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6302 - accuracy: 0.7738 - val_loss: 2.9687 - val_accuracy: 0.4704\n",
            "Epoch 149/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6394 - accuracy: 0.7712 - val_loss: 2.9972 - val_accuracy: 0.4587\n",
            "Epoch 150/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6259 - accuracy: 0.7750 - val_loss: 2.9567 - val_accuracy: 0.4714\n",
            "Epoch 151/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6190 - accuracy: 0.7757 - val_loss: 3.1661 - val_accuracy: 0.4648\n",
            "Epoch 152/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6191 - accuracy: 0.7761 - val_loss: 3.1750 - val_accuracy: 0.4621\n",
            "Epoch 153/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6148 - accuracy: 0.7771 - val_loss: 3.1893 - val_accuracy: 0.4663\n",
            "Epoch 154/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6302 - accuracy: 0.7715 - val_loss: 3.3099 - val_accuracy: 0.4610\n",
            "Epoch 155/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6151 - accuracy: 0.7771 - val_loss: 3.2353 - val_accuracy: 0.4597\n",
            "Epoch 156/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6236 - accuracy: 0.7760 - val_loss: 3.1391 - val_accuracy: 0.4626\n",
            "Epoch 157/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6131 - accuracy: 0.7789 - val_loss: 3.2989 - val_accuracy: 0.4594\n",
            "Epoch 158/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6167 - accuracy: 0.7768 - val_loss: 3.2979 - val_accuracy: 0.4634\n",
            "Epoch 159/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6227 - accuracy: 0.7755 - val_loss: 3.3511 - val_accuracy: 0.4623\n",
            "Epoch 160/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6075 - accuracy: 0.7800 - val_loss: 3.1622 - val_accuracy: 0.4649\n",
            "Epoch 161/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6067 - accuracy: 0.7802 - val_loss: 3.3253 - val_accuracy: 0.4589\n",
            "Epoch 162/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6115 - accuracy: 0.7775 - val_loss: 3.2553 - val_accuracy: 0.4645\n",
            "Epoch 163/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5965 - accuracy: 0.7840 - val_loss: 3.3963 - val_accuracy: 0.4650\n",
            "Epoch 164/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6194 - accuracy: 0.7742 - val_loss: 3.1524 - val_accuracy: 0.4587\n",
            "Epoch 165/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6033 - accuracy: 0.7836 - val_loss: 3.2057 - val_accuracy: 0.4675\n",
            "Epoch 166/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6051 - accuracy: 0.7820 - val_loss: 3.1856 - val_accuracy: 0.4643\n",
            "Epoch 167/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6025 - accuracy: 0.7846 - val_loss: 3.5363 - val_accuracy: 0.4530\n",
            "Epoch 168/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6123 - accuracy: 0.7805 - val_loss: 3.4015 - val_accuracy: 0.4599\n",
            "Epoch 169/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5883 - accuracy: 0.7890 - val_loss: 3.3954 - val_accuracy: 0.4629\n",
            "Epoch 170/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.5939 - accuracy: 0.7842 - val_loss: 3.4854 - val_accuracy: 0.4623\n",
            "Epoch 171/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6043 - accuracy: 0.7812 - val_loss: 3.2723 - val_accuracy: 0.4660\n",
            "Epoch 172/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5927 - accuracy: 0.7854 - val_loss: 3.4165 - val_accuracy: 0.4657\n",
            "Epoch 173/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5958 - accuracy: 0.7847 - val_loss: 3.4871 - val_accuracy: 0.4576\n",
            "Epoch 174/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.5878 - accuracy: 0.7876 - val_loss: 3.3959 - val_accuracy: 0.4677\n",
            "Epoch 175/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6008 - accuracy: 0.7821 - val_loss: 3.4619 - val_accuracy: 0.4669\n",
            "Epoch 176/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5915 - accuracy: 0.7865 - val_loss: 3.4119 - val_accuracy: 0.4598\n",
            "Epoch 177/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5910 - accuracy: 0.7878 - val_loss: 3.4017 - val_accuracy: 0.4595\n",
            "Epoch 178/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5799 - accuracy: 0.7908 - val_loss: 3.4751 - val_accuracy: 0.4649\n",
            "Epoch 179/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5925 - accuracy: 0.7877 - val_loss: 3.4252 - val_accuracy: 0.4685\n",
            "Epoch 180/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5898 - accuracy: 0.7894 - val_loss: 3.4335 - val_accuracy: 0.4625\n",
            "Epoch 181/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5880 - accuracy: 0.7886 - val_loss: 3.2948 - val_accuracy: 0.4648\n",
            "Epoch 182/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5843 - accuracy: 0.7878 - val_loss: 3.5410 - val_accuracy: 0.4513\n",
            "Epoch 183/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5876 - accuracy: 0.7900 - val_loss: 3.8062 - val_accuracy: 0.4533\n",
            "Epoch 184/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5751 - accuracy: 0.7917 - val_loss: 3.7586 - val_accuracy: 0.4552\n",
            "Epoch 185/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5741 - accuracy: 0.7934 - val_loss: 3.6495 - val_accuracy: 0.4623\n",
            "Epoch 186/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5971 - accuracy: 0.7853 - val_loss: 3.5700 - val_accuracy: 0.4572\n",
            "Epoch 187/300\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 0.5836 - accuracy: 0.7885 - val_loss: 3.5649 - val_accuracy: 0.4573\n",
            "Epoch 188/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5695 - accuracy: 0.7943 - val_loss: 3.5022 - val_accuracy: 0.4648\n",
            "Epoch 189/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5755 - accuracy: 0.7931 - val_loss: 3.5887 - val_accuracy: 0.4543\n",
            "Epoch 190/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5699 - accuracy: 0.7945 - val_loss: 3.8026 - val_accuracy: 0.4564\n",
            "Epoch 191/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5688 - accuracy: 0.7946 - val_loss: 3.5704 - val_accuracy: 0.4566\n",
            "Epoch 192/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5837 - accuracy: 0.7893 - val_loss: 3.6055 - val_accuracy: 0.4579\n",
            "Epoch 193/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5609 - accuracy: 0.7969 - val_loss: 3.7001 - val_accuracy: 0.4641\n",
            "Epoch 194/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5614 - accuracy: 0.7960 - val_loss: 3.7144 - val_accuracy: 0.4600\n",
            "Epoch 195/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5778 - accuracy: 0.7930 - val_loss: 3.6561 - val_accuracy: 0.4563\n",
            "Epoch 196/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5697 - accuracy: 0.7945 - val_loss: 3.6418 - val_accuracy: 0.4505\n",
            "Epoch 197/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5620 - accuracy: 0.7956 - val_loss: 3.6234 - val_accuracy: 0.4637\n",
            "Epoch 198/300\n",
            "1563/1563 [==============================] - 48s 30ms/step - loss: 0.5733 - accuracy: 0.7946 - val_loss: 3.6574 - val_accuracy: 0.4581\n",
            "Epoch 199/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5637 - accuracy: 0.7976 - val_loss: 3.8191 - val_accuracy: 0.4656\n",
            "Epoch 200/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5621 - accuracy: 0.7977 - val_loss: 3.7479 - val_accuracy: 0.4584\n",
            "Epoch 201/300\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5740 - accuracy: 0.7941 - val_loss: 3.6015 - val_accuracy: 0.4631\n",
            "Epoch 202/300\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5630 - accuracy: 0.7978 - val_loss: 3.8129 - val_accuracy: 0.4548\n",
            "Epoch 203/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5571 - accuracy: 0.7994 - val_loss: 3.6991 - val_accuracy: 0.4577\n",
            "Epoch 204/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5607 - accuracy: 0.7984 - val_loss: 3.7949 - val_accuracy: 0.4611\n",
            "Epoch 205/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5746 - accuracy: 0.7958 - val_loss: 3.7848 - val_accuracy: 0.4502\n",
            "Epoch 206/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5472 - accuracy: 0.8019 - val_loss: 3.9534 - val_accuracy: 0.4629\n",
            "Epoch 207/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5494 - accuracy: 0.8020 - val_loss: 3.9469 - val_accuracy: 0.4571\n",
            "Epoch 208/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5643 - accuracy: 0.7972 - val_loss: 3.8263 - val_accuracy: 0.4552\n",
            "Epoch 209/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5496 - accuracy: 0.7995 - val_loss: 4.1733 - val_accuracy: 0.4405\n",
            "Epoch 210/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5662 - accuracy: 0.7968 - val_loss: 3.9089 - val_accuracy: 0.4509\n",
            "Epoch 211/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5625 - accuracy: 0.7992 - val_loss: 3.6688 - val_accuracy: 0.4610\n",
            "Epoch 212/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5539 - accuracy: 0.7998 - val_loss: 3.9236 - val_accuracy: 0.4488\n",
            "Epoch 213/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5459 - accuracy: 0.8041 - val_loss: 3.8624 - val_accuracy: 0.4620\n",
            "Epoch 214/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5544 - accuracy: 0.8012 - val_loss: 4.1600 - val_accuracy: 0.4535\n",
            "Epoch 215/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5601 - accuracy: 0.7972 - val_loss: 3.9524 - val_accuracy: 0.4580\n",
            "Epoch 216/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5518 - accuracy: 0.8021 - val_loss: 3.9693 - val_accuracy: 0.4565\n",
            "Epoch 217/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5593 - accuracy: 0.8013 - val_loss: 3.9597 - val_accuracy: 0.4573\n",
            "Epoch 218/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5486 - accuracy: 0.8028 - val_loss: 3.8448 - val_accuracy: 0.4555\n",
            "Epoch 219/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5440 - accuracy: 0.8028 - val_loss: 3.9323 - val_accuracy: 0.4529\n",
            "Epoch 220/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5360 - accuracy: 0.8077 - val_loss: 3.9876 - val_accuracy: 0.4583\n",
            "Epoch 221/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5689 - accuracy: 0.7962 - val_loss: 3.8909 - val_accuracy: 0.4525\n",
            "Epoch 222/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5351 - accuracy: 0.8073 - val_loss: 3.9087 - val_accuracy: 0.4606\n",
            "Epoch 223/300\n",
            "1563/1563 [==============================] - 48s 30ms/step - loss: 0.5533 - accuracy: 0.8025 - val_loss: 4.1546 - val_accuracy: 0.4495\n",
            "Epoch 224/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5363 - accuracy: 0.8075 - val_loss: 4.1444 - val_accuracy: 0.4584\n",
            "Epoch 225/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5460 - accuracy: 0.8051 - val_loss: 4.1098 - val_accuracy: 0.4511\n",
            "Epoch 226/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5472 - accuracy: 0.8025 - val_loss: 4.1112 - val_accuracy: 0.4529\n",
            "Epoch 227/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5334 - accuracy: 0.8082 - val_loss: 4.0552 - val_accuracy: 0.4602\n",
            "Epoch 228/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5334 - accuracy: 0.8098 - val_loss: 4.0374 - val_accuracy: 0.4539\n",
            "Epoch 229/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5404 - accuracy: 0.8063 - val_loss: 4.1128 - val_accuracy: 0.4487\n",
            "Epoch 230/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5405 - accuracy: 0.8072 - val_loss: 4.0238 - val_accuracy: 0.4542\n",
            "Epoch 231/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5481 - accuracy: 0.8019 - val_loss: 4.0245 - val_accuracy: 0.4536\n",
            "Epoch 232/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5343 - accuracy: 0.8071 - val_loss: 4.1304 - val_accuracy: 0.4564\n",
            "Epoch 233/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5415 - accuracy: 0.8093 - val_loss: 4.2223 - val_accuracy: 0.4548\n",
            "Epoch 234/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5298 - accuracy: 0.8089 - val_loss: 3.9976 - val_accuracy: 0.4522\n",
            "Epoch 235/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5334 - accuracy: 0.8099 - val_loss: 4.1013 - val_accuracy: 0.4471\n",
            "Epoch 236/300\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 0.5423 - accuracy: 0.8044 - val_loss: 4.1432 - val_accuracy: 0.4591\n",
            "Epoch 237/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5449 - accuracy: 0.8084 - val_loss: 3.8968 - val_accuracy: 0.4494\n",
            "Epoch 238/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5447 - accuracy: 0.8043 - val_loss: 4.0326 - val_accuracy: 0.4546\n",
            "Epoch 239/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5240 - accuracy: 0.8104 - val_loss: 4.2269 - val_accuracy: 0.4507\n",
            "Epoch 240/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5331 - accuracy: 0.8088 - val_loss: 4.3011 - val_accuracy: 0.4484\n",
            "Epoch 241/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5345 - accuracy: 0.8082 - val_loss: 4.1995 - val_accuracy: 0.4466\n",
            "Epoch 242/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5376 - accuracy: 0.8071 - val_loss: 4.3185 - val_accuracy: 0.4453\n",
            "Epoch 243/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5183 - accuracy: 0.8154 - val_loss: 4.1883 - val_accuracy: 0.4479\n",
            "Epoch 244/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5379 - accuracy: 0.8085 - val_loss: 3.9374 - val_accuracy: 0.4517\n",
            "Epoch 245/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5365 - accuracy: 0.8082 - val_loss: 4.3645 - val_accuracy: 0.4557\n",
            "Epoch 246/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5170 - accuracy: 0.8152 - val_loss: 4.1899 - val_accuracy: 0.4566\n",
            "Epoch 247/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5434 - accuracy: 0.8056 - val_loss: 4.3583 - val_accuracy: 0.4507\n",
            "Epoch 248/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5171 - accuracy: 0.8137 - val_loss: 4.2554 - val_accuracy: 0.4535\n",
            "Epoch 249/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5266 - accuracy: 0.8105 - val_loss: 4.3050 - val_accuracy: 0.4560\n",
            "Epoch 250/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5455 - accuracy: 0.8059 - val_loss: 4.3334 - val_accuracy: 0.4549\n",
            "Epoch 251/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5094 - accuracy: 0.8163 - val_loss: 4.2743 - val_accuracy: 0.4576\n",
            "Epoch 252/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5301 - accuracy: 0.8105 - val_loss: 4.3484 - val_accuracy: 0.4543\n",
            "Epoch 253/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5175 - accuracy: 0.8164 - val_loss: 4.4961 - val_accuracy: 0.4509\n",
            "Epoch 254/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5287 - accuracy: 0.8093 - val_loss: 4.4093 - val_accuracy: 0.4591\n",
            "Epoch 255/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5354 - accuracy: 0.8073 - val_loss: 4.2292 - val_accuracy: 0.4579\n",
            "Epoch 256/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5363 - accuracy: 0.8097 - val_loss: 4.2319 - val_accuracy: 0.4513\n",
            "Epoch 257/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5092 - accuracy: 0.8183 - val_loss: 4.3204 - val_accuracy: 0.4543\n",
            "Epoch 258/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5279 - accuracy: 0.8110 - val_loss: 4.3903 - val_accuracy: 0.4536\n",
            "Epoch 259/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5194 - accuracy: 0.8136 - val_loss: 4.4425 - val_accuracy: 0.4500\n",
            "Epoch 260/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5372 - accuracy: 0.8090 - val_loss: 4.5278 - val_accuracy: 0.4554\n",
            "Epoch 261/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5151 - accuracy: 0.8151 - val_loss: 4.5082 - val_accuracy: 0.4563\n",
            "Epoch 262/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5208 - accuracy: 0.8146 - val_loss: 4.3145 - val_accuracy: 0.4575\n",
            "Epoch 263/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5271 - accuracy: 0.8128 - val_loss: 4.6035 - val_accuracy: 0.4504\n",
            "Epoch 264/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.5070 - accuracy: 0.8185 - val_loss: 4.5535 - val_accuracy: 0.4530\n",
            "Epoch 265/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.5056 - accuracy: 0.8187 - val_loss: 4.6770 - val_accuracy: 0.4512\n",
            "Epoch 266/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5197 - accuracy: 0.8145 - val_loss: 4.4699 - val_accuracy: 0.4481\n",
            "Epoch 267/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5238 - accuracy: 0.8143 - val_loss: 4.3077 - val_accuracy: 0.4602\n",
            "Epoch 268/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5148 - accuracy: 0.8175 - val_loss: 4.5807 - val_accuracy: 0.4516\n",
            "Epoch 269/300\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.5191 - accuracy: 0.8151 - val_loss: 4.6810 - val_accuracy: 0.4571\n",
            "Epoch 270/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5080 - accuracy: 0.8182 - val_loss: 4.7157 - val_accuracy: 0.4495\n",
            "Epoch 271/300\n",
            "1563/1563 [==============================] - 48s 30ms/step - loss: 0.5162 - accuracy: 0.8165 - val_loss: 4.4954 - val_accuracy: 0.4482\n",
            "Epoch 272/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5070 - accuracy: 0.8185 - val_loss: 4.5508 - val_accuracy: 0.4499\n",
            "Epoch 273/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5059 - accuracy: 0.8198 - val_loss: 4.6373 - val_accuracy: 0.4520\n",
            "Epoch 274/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5247 - accuracy: 0.8136 - val_loss: 4.4365 - val_accuracy: 0.4527\n",
            "Epoch 275/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5118 - accuracy: 0.8188 - val_loss: 4.5342 - val_accuracy: 0.4582\n",
            "Epoch 276/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5215 - accuracy: 0.8166 - val_loss: 4.5158 - val_accuracy: 0.4549\n",
            "Epoch 277/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5078 - accuracy: 0.8165 - val_loss: 4.6642 - val_accuracy: 0.4518\n",
            "Epoch 278/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5140 - accuracy: 0.8163 - val_loss: 4.5469 - val_accuracy: 0.4496\n",
            "Epoch 279/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5068 - accuracy: 0.8183 - val_loss: 4.4609 - val_accuracy: 0.4591\n",
            "Epoch 280/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5158 - accuracy: 0.8160 - val_loss: 4.6995 - val_accuracy: 0.4577\n",
            "Epoch 281/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5101 - accuracy: 0.8183 - val_loss: 4.4448 - val_accuracy: 0.4624\n",
            "Epoch 282/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5057 - accuracy: 0.8204 - val_loss: 4.4806 - val_accuracy: 0.4540\n",
            "Epoch 283/300\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5079 - accuracy: 0.8184 - val_loss: 4.6138 - val_accuracy: 0.4526\n",
            "Epoch 284/300\n",
            "1563/1563 [==============================] - 48s 30ms/step - loss: 0.5011 - accuracy: 0.8210 - val_loss: 4.5714 - val_accuracy: 0.4499\n",
            "Epoch 285/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.4941 - accuracy: 0.8220 - val_loss: 4.7231 - val_accuracy: 0.4526\n",
            "Epoch 286/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5174 - accuracy: 0.8173 - val_loss: 4.3189 - val_accuracy: 0.4578\n",
            "Epoch 287/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.4975 - accuracy: 0.8215 - val_loss: 4.7779 - val_accuracy: 0.4540\n",
            "Epoch 288/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5118 - accuracy: 0.8206 - val_loss: 4.5297 - val_accuracy: 0.4507\n",
            "Epoch 289/300\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5136 - accuracy: 0.8181 - val_loss: 4.8727 - val_accuracy: 0.4525\n",
            "Epoch 290/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.4890 - accuracy: 0.8239 - val_loss: 4.6603 - val_accuracy: 0.4533\n",
            "Epoch 291/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5128 - accuracy: 0.8181 - val_loss: 4.3610 - val_accuracy: 0.4554\n",
            "Epoch 292/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5087 - accuracy: 0.8190 - val_loss: 5.0139 - val_accuracy: 0.4494\n",
            "Epoch 293/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4996 - accuracy: 0.8234 - val_loss: 4.9949 - val_accuracy: 0.4501\n",
            "Epoch 294/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5165 - accuracy: 0.8173 - val_loss: 4.8147 - val_accuracy: 0.4585\n",
            "Epoch 295/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4874 - accuracy: 0.8254 - val_loss: 4.6967 - val_accuracy: 0.4558\n",
            "Epoch 296/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5006 - accuracy: 0.8216 - val_loss: 4.8925 - val_accuracy: 0.4451\n",
            "Epoch 297/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5081 - accuracy: 0.8209 - val_loss: 4.9933 - val_accuracy: 0.4477\n",
            "Epoch 298/300\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4960 - accuracy: 0.8246 - val_loss: 4.7296 - val_accuracy: 0.4537\n",
            "Epoch 299/300\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.4944 - accuracy: 0.8237 - val_loss: 4.7090 - val_accuracy: 0.4543\n",
            "Epoch 300/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4820 - accuracy: 0.8272 - val_loss: 4.5310 - val_accuracy: 0.4528\n"
          ]
        }
      ],
      "source": [
        "# Build the neural network model with three hidden layers\n",
        "model1 = models.Sequential()\n",
        "model1.add(layers.Flatten(input_shape=(32, 32, 3)))  # Flatten the image\n",
        "model1.add(layers.Dense(512, activation='relu'))\n",
        "model1.add(layers.Dense(256, activation='relu'))\n",
        "model1.add(layers.Dense(128, activation='relu'))\n",
        "model1.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "start_time1 = time.time()\n",
        "history1 = model1.fit(train_images, train_labels, epochs=300, validation_data=(test_images, test_labels))\n",
        "end_time1 = time.time()\n",
        "training_time1 = end_time1 - start_time1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB0r0cz73kwx",
        "outputId": "b91f588c-fc37-4178-9231-ec7822b43173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 13ms/step - loss: 4.5310 - accuracy: 0.4528\n",
            "Training Time: 13284.266102075577 seconds\n",
            "Training Loss: 0.48198071122169495\n",
            "Test Accuracy: 0.4528000056743622\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "test_loss1, test_accuracy1 = model1.evaluate(test_images, test_labels)\n",
        "\n",
        "# Print results\n",
        "print(f'Training Time: {training_time1} seconds')\n",
        "print(f'Training Loss: {history1.history[\"loss\"][-1]}')\n",
        "print(f'Test Accuracy: {test_accuracy1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OHfZrpz9KhFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, we clearly see overfitting. There is huge difference between the training accuracy and validation accuracy which is a clear indication of overfitting."
      ],
      "metadata": {
        "id": "TjBMzb3mLXIY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMiHVG9pLXy0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
