{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabhinav3/Intro_to_ML/blob/main/Abhinav_HW7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4P-5wSHEQD6"
      },
      "source": [
        "### 1a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXwAE8f2LhIh",
        "outputId": "171b439c-faae-4468-d3b7-6868ddf08e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "957/957 [==============================] - 39s 39ms/step - loss: 0.0776 - accuracy: 0.9760 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
            "Epoch 2/300\n",
            "957/957 [==============================] - 35s 37ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0100 - val_accuracy: 0.9965\n",
            "Epoch 3/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
            "Epoch 4/300\n",
            "957/957 [==============================] - 36s 37ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.0064 - val_accuracy: 0.9973\n",
            "Epoch 5/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
            "Epoch 6/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0063 - val_accuracy: 0.9982\n",
            "Epoch 7/300\n",
            "957/957 [==============================] - 36s 37ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
            "Epoch 8/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0111 - val_accuracy: 0.9971\n",
            "Epoch 9/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0099 - val_accuracy: 0.9975\n",
            "Epoch 10/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9982\n",
            "Epoch 11/300\n",
            "957/957 [==============================] - 35s 37ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0133 - val_accuracy: 0.9969\n",
            "Epoch 12/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
            "Epoch 13/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 8.2251e-04 - accuracy: 0.9998 - val_loss: 0.0098 - val_accuracy: 0.9979\n",
            "Epoch 14/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0108 - val_accuracy: 0.9979\n",
            "Epoch 15/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0089 - val_accuracy: 0.9979\n",
            "Epoch 16/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0075 - val_accuracy: 0.9977\n",
            "Epoch 17/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
            "Epoch 18/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 3.8142e-04 - accuracy: 0.9999 - val_loss: 0.0052 - val_accuracy: 0.9988\n",
            "Epoch 19/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 1.9645e-05 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9990\n",
            "Epoch 20/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 4.8934e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9990\n",
            "Epoch 21/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 2.1759e-06 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9986\n",
            "Epoch 22/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 1.2718e-06 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9986\n",
            "Epoch 23/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 7.7348e-07 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9986\n",
            "Epoch 24/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 4.7331e-07 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9988\n",
            "Epoch 25/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 2.8786e-07 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9988\n",
            "Epoch 26/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 1.7247e-07 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9988\n",
            "Epoch 27/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 1.0374e-07 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9988\n",
            "Epoch 28/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 6.2296e-08 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9988\n",
            "Epoch 29/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 3.6967e-08 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9988\n",
            "Epoch 30/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 2.2259e-08 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9988\n",
            "Epoch 31/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 1.3313e-08 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9988\n",
            "Epoch 32/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 8.1704e-09 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9988\n",
            "Epoch 33/300\n",
            "957/957 [==============================] - 36s 37ms/step - loss: 5.1236e-09 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9986\n",
            "Epoch 34/300\n",
            "957/957 [==============================] - 35s 37ms/step - loss: 3.1521e-09 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9986\n",
            "Epoch 35/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 2.0572e-09 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9986\n",
            "Epoch 36/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 1.2429e-09 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9986\n",
            "Epoch 37/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 8.6496e-10 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9986\n",
            "Epoch 38/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 5.7664e-10 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9986\n",
            "Epoch 39/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 3.7014e-10 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9986\n",
            "Epoch 40/300\n",
            "957/957 [==============================] - 35s 37ms/step - loss: 2.5715e-10 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9986\n",
            "Epoch 41/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 1.8702e-10 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9986\n",
            "Epoch 42/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 1.2858e-10 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 43/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 9.7406e-11 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 44/300\n",
            "957/957 [==============================] - 36s 37ms/step - loss: 6.2340e-11 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 45/300\n",
            "957/957 [==============================] - 35s 37ms/step - loss: 4.2859e-11 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 46/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 3.1170e-11 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9986\n",
            "Epoch 47/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 2.3377e-11 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 48/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 1.5585e-11 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 49/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 1.5585e-11 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 50/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 1.5585e-11 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 51/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 1.1689e-11 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 52/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 3.8962e-12 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 53/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 1.5585e-11 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 54/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 3.8962e-12 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 55/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 7.7925e-12 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 56/300\n",
            "957/957 [==============================] - 35s 37ms/step - loss: 7.7925e-12 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 57/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 3.8962e-12 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 58/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 59/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 60/300\n",
            "957/957 [==============================] - 35s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 61/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 62/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 3.8962e-12 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 63/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 3.8962e-12 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 64/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 3.8962e-12 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 65/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 66/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 67/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 68/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 69/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 70/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 71/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 72/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 73/300\n",
            "957/957 [==============================] - 36s 38ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 74/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 75/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 76/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 77/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 78/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 79/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 80/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 81/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 82/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9986\n",
            "Epoch 83/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 84/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 85/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 86/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 87/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 88/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 89/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9986\n",
            "Epoch 90/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 91/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 92/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 93/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 94/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 95/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 96/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 97/300\n",
            "957/957 [==============================] - 35s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
            "Epoch 98/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9986\n",
            "Epoch 99/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9986\n",
            "Epoch 100/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9986\n",
            "Epoch 101/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9986\n",
            "Epoch 102/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9986\n",
            "Epoch 103/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9986\n",
            "Epoch 104/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9986\n",
            "Epoch 105/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9986\n",
            "Epoch 106/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9986\n",
            "Epoch 107/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9986\n",
            "Epoch 108/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9986\n",
            "Epoch 109/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9986\n",
            "Epoch 110/300\n",
            "957/957 [==============================] - 34s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9986\n",
            "Epoch 111/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9986\n",
            "Epoch 112/300\n",
            "957/957 [==============================] - 35s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9986\n",
            "Epoch 113/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9986\n",
            "Epoch 114/300\n",
            "957/957 [==============================] - 36s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9986\n",
            "Epoch 115/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9986\n",
            "Epoch 116/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
            "Epoch 117/300\n",
            "957/957 [==============================] - 35s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
            "Epoch 118/300\n",
            "957/957 [==============================] - 35s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
            "Epoch 119/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
            "Epoch 120/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
            "Epoch 121/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
            "Epoch 122/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
            "Epoch 123/300\n",
            "957/957 [==============================] - 32s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
            "Epoch 124/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
            "Epoch 125/300\n",
            "957/957 [==============================] - 31s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9986\n",
            "Epoch 126/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
            "Epoch 127/300\n",
            "957/957 [==============================] - 32s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
            "Epoch 128/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
            "Epoch 129/300\n",
            "957/957 [==============================] - 31s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
            "Epoch 130/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
            "Epoch 131/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
            "Epoch 132/300\n",
            "957/957 [==============================] - 32s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
            "Epoch 133/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
            "Epoch 134/300\n",
            "957/957 [==============================] - 32s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
            "Epoch 135/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
            "Epoch 136/300\n",
            "957/957 [==============================] - 32s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 137/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 138/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 139/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 140/300\n",
            "957/957 [==============================] - 31s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 141/300\n",
            "957/957 [==============================] - 33s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 142/300\n",
            "957/957 [==============================] - 31s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 143/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 144/300\n",
            "957/957 [==============================] - 30s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 145/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 146/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 147/300\n",
            "957/957 [==============================] - 31s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
            "Epoch 148/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 149/300\n",
            "957/957 [==============================] - 32s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 150/300\n",
            "957/957 [==============================] - 31s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 151/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 152/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 153/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 154/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 155/300\n",
            "957/957 [==============================] - 31s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 156/300\n",
            "957/957 [==============================] - 32s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 157/300\n",
            "957/957 [==============================] - 34s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 158/300\n",
            "957/957 [==============================] - 31s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 159/300\n",
            "957/957 [==============================] - 33s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 160/300\n",
            "957/957 [==============================] - 32s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9986\n",
            "Epoch 161/300\n",
            "531/957 [===============>..............] - ETA: 13s - loss: 0.0000e+00 - accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Keep only the samples corresponding to classes 0 to 4\n",
        "train_mask = (y_train <= 4)\n",
        "test_mask = (y_test <= 4)\n",
        "\n",
        "x_train, y_train = x_train[train_mask], y_train[train_mask]\n",
        "x_test, y_test = x_test[test_mask], y_test[test_mask]\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Expand dimensions to add a channel dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=5)\n",
        "y_test = to_categorical(y_test, num_classes=5)\n",
        "\n",
        "# Build the CNN model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))  # Adjust output classes to 5\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model for 300 epochs\n",
        "start_time = time.time()\n",
        "history = model.fit(x_train, y_train, epochs=300, validation_data=(x_test, y_test))\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "eval_loss, eval_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print(f\"Training Time: {training_time} seconds\")\n",
        "print(f\"Training Loss after 300 epochs: {history.history['loss'][-1]}\")\n",
        "print(f\"Evaluation Accuracy after 300 epochs: {eval_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE3llu_oETDg"
      },
      "source": [
        "### 1b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpmzopsdxOjf"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, models\n",
        "# from tensorflow.keras.datasets import mnist\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# # Load and preprocess MNIST dataset\n",
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# # Keep only the samples corresponding to classes 0 to 4\n",
        "# train_mask = (y_train <= 4)\n",
        "# test_mask = (y_test <= 4)\n",
        "\n",
        "# x_train, y_train = x_train[train_mask], y_train[train_mask]\n",
        "# x_test, y_test = x_test[test_mask], y_test[test_mask]\n",
        "\n",
        "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# # Expand dimensions to add a channel dimension\n",
        "# x_train = x_train[..., tf.newaxis]\n",
        "# x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "# # Convert labels to one-hot encoding\n",
        "# y_train = to_categorical(y_train, num_classes=5)\n",
        "# y_test = to_categorical(y_test, num_classes=5)\n",
        "\n",
        "# Build the extended CNN model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))  # Additional convolution layer\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))  # Adjusted fully connected layer\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))  # Adjust output classes to 5\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model for 300 epochs\n",
        "start_time = time.time()\n",
        "history = model.fit(x_train, y_train, epochs=300, validation_data=(x_test, y_test))\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "eval_loss, eval_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print(f\"Training Time: {training_time} seconds\")\n",
        "print(f\"Training Loss after 300 epochs: {history.history['loss'][-1]}\")\n",
        "print(f\"Evaluation Accuracy after 300 epochs: {eval_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mDbRq9rEUsB"
      },
      "source": [
        "### 2a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w27QLjG-ZdOU",
        "outputId": "f93992b1-b523-4625-f27c-e82b77e25390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Keep only the samples corresponding to classes 0 to 4\n",
        "train_mask = (y_train <= 4)\n",
        "test_mask = (y_test <= 4)\n",
        "\n",
        "x_train, y_train = x_train[train_mask], y_train[train_mask]\n",
        "x_test, y_test = x_test[test_mask], y_test[test_mask]\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Expand dimensions to add a channel dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=5)\n",
        "y_test = to_categorical(y_test, num_classes=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JkBlDHEEWBb"
      },
      "source": [
        "### 2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nAtPqZVucvk3",
        "outputId": "95a7587a-ce3a-4b89-e3c2-4dc1721c6873"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.12.0'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnDxsXjZc0mp",
        "outputId": "e9be6964-8f89-467b-fbca-c83bda5abfdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_135 (Conv2D)         (None, 14, 14, 64)        3200      \n",
            "                                                                 \n",
            " batch_normalization_144 (Ba  (None, 14, 14, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_130 (Activation)  (None, 14, 14, 64)       0         \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_138 (Conv2D)         (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_147 (Ba  (None, 7, 7, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_133 (Activation)  (None, 7, 7, 64)         0         \n",
            "                                                                 \n",
            " conv2d_141 (Conv2D)         (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_150 (Ba  (None, 7, 7, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_136 (Activation)  (None, 7, 7, 64)         0         \n",
            "                                                                 \n",
            " conv2d_144 (Conv2D)         (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_153 (Ba  (None, 7, 7, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_139 (Activation)  (None, 7, 7, 64)         0         \n",
            "                                                                 \n",
            " conv2d_147 (Conv2D)         (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_156 (Ba  (None, 7, 7, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_142 (Activation)  (None, 7, 7, 64)         0         \n",
            "                                                                 \n",
            " conv2d_150 (Conv2D)         (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_159 (Ba  (None, 7, 7, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_145 (Activation)  (None, 7, 7, 64)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_8   (None, 64)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 190,026\n",
            "Trainable params: 189,258\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "938/938 [==============================] - 166s 173ms/step - loss: 0.1333 - accuracy: 0.9650 - val_loss: 0.3675 - val_accuracy: 0.8788\n",
            "Epoch 2/300\n",
            "938/938 [==============================] - 166s 177ms/step - loss: 0.0481 - accuracy: 0.9857 - val_loss: 0.1001 - val_accuracy: 0.9692\n",
            "Epoch 3/300\n",
            "938/938 [==============================] - 164s 175ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 0.0399 - val_accuracy: 0.9873\n",
            "Epoch 4/300\n",
            "938/938 [==============================] - 166s 177ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.0688 - val_accuracy: 0.9791\n",
            "Epoch 5/300\n",
            "938/938 [==============================] - 164s 175ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.0437 - val_accuracy: 0.9867\n",
            "Epoch 6/300\n",
            "938/938 [==============================] - 162s 173ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.0300 - val_accuracy: 0.9903\n",
            "Epoch 7/300\n",
            "938/938 [==============================] - 160s 170ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0676 - val_accuracy: 0.9797\n",
            "Epoch 8/300\n",
            "938/938 [==============================] - 167s 178ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.0307 - val_accuracy: 0.9896\n",
            "Epoch 9/300\n",
            "938/938 [==============================] - 158s 169ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0307 - val_accuracy: 0.9899\n",
            "Epoch 10/300\n",
            "938/938 [==============================] - 158s 168ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0778 - val_accuracy: 0.9781\n",
            "Epoch 11/300\n",
            "938/938 [==============================] - 164s 175ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0475 - val_accuracy: 0.9868\n",
            "Epoch 12/300\n",
            "938/938 [==============================] - 160s 171ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0243 - val_accuracy: 0.9924\n",
            "Epoch 13/300\n",
            "938/938 [==============================] - 160s 170ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0401 - val_accuracy: 0.9880\n",
            "Epoch 14/300\n",
            "938/938 [==============================] - 163s 174ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0529 - val_accuracy: 0.9847\n",
            "Epoch 15/300\n",
            "938/938 [==============================] - 166s 177ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0214 - val_accuracy: 0.9934\n",
            "Epoch 16/300\n",
            "938/938 [==============================] - 159s 170ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0256 - val_accuracy: 0.9931\n",
            "Epoch 17/300\n",
            "938/938 [==============================] - 160s 170ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0304 - val_accuracy: 0.9908\n",
            "Epoch 18/300\n",
            "938/938 [==============================] - 159s 170ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0224 - val_accuracy: 0.9934\n",
            "Epoch 19/300\n",
            "938/938 [==============================] - 165s 176ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0478 - val_accuracy: 0.9860\n",
            "Epoch 20/300\n",
            "938/938 [==============================] - 159s 170ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0210 - val_accuracy: 0.9925\n",
            "Epoch 21/300\n",
            "938/938 [==============================] - 163s 174ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0422 - val_accuracy: 0.9893\n",
            "Epoch 22/300\n",
            "938/938 [==============================] - 163s 174ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0367 - val_accuracy: 0.9896\n",
            "Epoch 23/300\n",
            "938/938 [==============================] - 166s 177ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0418 - val_accuracy: 0.9886\n",
            "Epoch 24/300\n",
            "938/938 [==============================] - 164s 175ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0306 - val_accuracy: 0.9913\n",
            "Epoch 25/300\n",
            "938/938 [==============================] - 162s 172ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0323 - val_accuracy: 0.9913\n",
            "Epoch 26/300\n",
            "938/938 [==============================] - 159s 169ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0315 - val_accuracy: 0.9918\n",
            "Epoch 27/300\n",
            "938/938 [==============================] - 159s 169ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0477 - val_accuracy: 0.9890\n",
            "Epoch 28/300\n",
            "938/938 [==============================] - 160s 170ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0390 - val_accuracy: 0.9901\n",
            "Epoch 29/300\n",
            "938/938 [==============================] - 158s 169ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0318 - val_accuracy: 0.9920\n",
            "Epoch 30/300\n",
            "938/938 [==============================] - 164s 175ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0277 - val_accuracy: 0.9928\n",
            "Epoch 31/300\n",
            "938/938 [==============================] - 161s 172ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0260 - val_accuracy: 0.9931\n",
            "Epoch 32/300\n",
            "938/938 [==============================] - 159s 169ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0258 - val_accuracy: 0.9935\n",
            "Epoch 33/300\n",
            "938/938 [==============================] - 160s 170ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0357 - val_accuracy: 0.9908\n",
            "Epoch 34/300\n",
            "938/938 [==============================] - 159s 170ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0209 - val_accuracy: 0.9951\n",
            "Epoch 35/300\n",
            "938/938 [==============================] - 163s 173ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0256 - val_accuracy: 0.9933\n",
            "Epoch 36/300\n",
            "938/938 [==============================] - 159s 170ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0418 - val_accuracy: 0.9910\n",
            "Epoch 37/300\n",
            "938/938 [==============================] - 158s 168ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0199 - val_accuracy: 0.9942\n",
            "Epoch 38/300\n",
            "938/938 [==============================] - 163s 174ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0367 - val_accuracy: 0.9923\n",
            "Epoch 39/300\n",
            "938/938 [==============================] - 165s 176ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9929\n",
            "Epoch 40/300\n",
            "938/938 [==============================] - 162s 172ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0215 - val_accuracy: 0.9943\n",
            "Epoch 41/300\n",
            "938/938 [==============================] - 163s 174ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0575 - val_accuracy: 0.9870\n",
            "Epoch 42/300\n",
            "938/938 [==============================] - 159s 169ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0224 - val_accuracy: 0.9943\n",
            "Epoch 43/300\n",
            "938/938 [==============================] - 164s 175ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0260 - val_accuracy: 0.9936\n",
            "Epoch 44/300\n",
            "938/938 [==============================] - 152s 161ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0332 - val_accuracy: 0.9912\n",
            "Epoch 45/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0336 - val_accuracy: 0.9918\n",
            "Epoch 46/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0305 - val_accuracy: 0.9936\n",
            "Epoch 47/300\n",
            "938/938 [==============================] - 147s 156ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0341 - val_accuracy: 0.9924\n",
            "Epoch 48/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0216 - val_accuracy: 0.9944\n",
            "Epoch 49/300\n",
            "938/938 [==============================] - 158s 169ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0497 - val_accuracy: 0.9884\n",
            "Epoch 50/300\n",
            "938/938 [==============================] - 153s 163ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0223 - val_accuracy: 0.9950\n",
            "Epoch 51/300\n",
            "938/938 [==============================] - 155s 165ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0297 - val_accuracy: 0.9944\n",
            "Epoch 52/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0286 - val_accuracy: 0.9933\n",
            "Epoch 53/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0307 - val_accuracy: 0.9937\n",
            "Epoch 54/300\n",
            "938/938 [==============================] - 153s 163ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0270 - val_accuracy: 0.9943\n",
            "Epoch 55/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0250 - val_accuracy: 0.9951\n",
            "Epoch 56/300\n",
            "938/938 [==============================] - 156s 166ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0317 - val_accuracy: 0.9929\n",
            "Epoch 57/300\n",
            "938/938 [==============================] - 158s 169ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0515 - val_accuracy: 0.9890\n",
            "Epoch 58/300\n",
            "938/938 [==============================] - 151s 161ms/step - loss: 7.9233e-04 - accuracy: 0.9998 - val_loss: 0.0274 - val_accuracy: 0.9931\n",
            "Epoch 59/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0297 - val_accuracy: 0.9939\n",
            "Epoch 60/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0247 - val_accuracy: 0.9946\n",
            "Epoch 61/300\n",
            "938/938 [==============================] - 153s 163ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0288 - val_accuracy: 0.9937\n",
            "Epoch 62/300\n",
            "938/938 [==============================] - 157s 167ms/step - loss: 7.1990e-04 - accuracy: 0.9998 - val_loss: 0.0276 - val_accuracy: 0.9945\n",
            "Epoch 63/300\n",
            "938/938 [==============================] - 154s 164ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0255 - val_accuracy: 0.9939\n",
            "Epoch 64/300\n",
            "938/938 [==============================] - 152s 163ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0298 - val_accuracy: 0.9934\n",
            "Epoch 65/300\n",
            "938/938 [==============================] - 157s 167ms/step - loss: 8.1838e-04 - accuracy: 0.9998 - val_loss: 0.0226 - val_accuracy: 0.9952\n",
            "Epoch 66/300\n",
            "938/938 [==============================] - 157s 168ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0226 - val_accuracy: 0.9947\n",
            "Epoch 67/300\n",
            "938/938 [==============================] - 151s 161ms/step - loss: 9.7262e-04 - accuracy: 0.9997 - val_loss: 0.0258 - val_accuracy: 0.9943\n",
            "Epoch 68/300\n",
            "938/938 [==============================] - 162s 172ms/step - loss: 5.6564e-04 - accuracy: 0.9998 - val_loss: 0.0298 - val_accuracy: 0.9936\n",
            "Epoch 69/300\n",
            "938/938 [==============================] - 164s 175ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0546 - val_accuracy: 0.9888\n",
            "Epoch 70/300\n",
            "938/938 [==============================] - 155s 165ms/step - loss: 9.6618e-04 - accuracy: 0.9997 - val_loss: 0.0243 - val_accuracy: 0.9949\n",
            "Epoch 71/300\n",
            "938/938 [==============================] - 153s 163ms/step - loss: 5.3377e-04 - accuracy: 0.9999 - val_loss: 0.0380 - val_accuracy: 0.9914\n",
            "Epoch 72/300\n",
            "938/938 [==============================] - 153s 164ms/step - loss: 7.4545e-04 - accuracy: 0.9998 - val_loss: 0.0370 - val_accuracy: 0.9932\n",
            "Epoch 73/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0284 - val_accuracy: 0.9929\n",
            "Epoch 74/300\n",
            "938/938 [==============================] - 156s 166ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0308 - val_accuracy: 0.9938\n",
            "Epoch 75/300\n",
            "938/938 [==============================] - 158s 168ms/step - loss: 7.5277e-04 - accuracy: 0.9998 - val_loss: 0.0283 - val_accuracy: 0.9935\n",
            "Epoch 76/300\n",
            "938/938 [==============================] - 153s 163ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0198 - val_accuracy: 0.9946\n",
            "Epoch 77/300\n",
            "938/938 [==============================] - 158s 168ms/step - loss: 8.2620e-04 - accuracy: 0.9997 - val_loss: 0.0289 - val_accuracy: 0.9931\n",
            "Epoch 78/300\n",
            "938/938 [==============================] - 159s 170ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0306 - val_accuracy: 0.9930\n",
            "Epoch 79/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0228 - val_accuracy: 0.9950\n",
            "Epoch 80/300\n",
            "938/938 [==============================] - 155s 165ms/step - loss: 6.2654e-05 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9951\n",
            "Epoch 81/300\n",
            "938/938 [==============================] - 151s 161ms/step - loss: 7.2874e-05 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9947\n",
            "Epoch 82/300\n",
            "938/938 [==============================] - 154s 164ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0354 - val_accuracy: 0.9932\n",
            "Epoch 83/300\n",
            "938/938 [==============================] - 155s 166ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0285 - val_accuracy: 0.9947\n",
            "Epoch 84/300\n",
            "938/938 [==============================] - 158s 168ms/step - loss: 7.6285e-04 - accuracy: 0.9997 - val_loss: 0.0217 - val_accuracy: 0.9952\n",
            "Epoch 85/300\n",
            "938/938 [==============================] - 153s 163ms/step - loss: 8.6711e-04 - accuracy: 0.9998 - val_loss: 0.0257 - val_accuracy: 0.9946\n",
            "Epoch 86/300\n",
            "938/938 [==============================] - 149s 159ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0259 - val_accuracy: 0.9947\n",
            "Epoch 87/300\n",
            "938/938 [==============================] - 154s 164ms/step - loss: 5.6643e-04 - accuracy: 0.9998 - val_loss: 0.0317 - val_accuracy: 0.9935\n",
            "Epoch 88/300\n",
            "938/938 [==============================] - 149s 159ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0246 - val_accuracy: 0.9949\n",
            "Epoch 89/300\n",
            "938/938 [==============================] - 155s 165ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0300 - val_accuracy: 0.9941\n",
            "Epoch 90/300\n",
            "938/938 [==============================] - 156s 166ms/step - loss: 7.5886e-04 - accuracy: 0.9998 - val_loss: 0.0394 - val_accuracy: 0.9922\n",
            "Epoch 91/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0241 - val_accuracy: 0.9945\n",
            "Epoch 92/300\n",
            "938/938 [==============================] - 148s 158ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0291 - val_accuracy: 0.9943\n",
            "Epoch 93/300\n",
            "938/938 [==============================] - 157s 167ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0273 - val_accuracy: 0.9948\n",
            "Epoch 94/300\n",
            "938/938 [==============================] - 156s 166ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0321 - val_accuracy: 0.9940\n",
            "Epoch 95/300\n",
            "938/938 [==============================] - 149s 159ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0275 - val_accuracy: 0.9939\n",
            "Epoch 96/300\n",
            "938/938 [==============================] - 156s 166ms/step - loss: 5.3491e-04 - accuracy: 0.9998 - val_loss: 0.0348 - val_accuracy: 0.9934\n",
            "Epoch 97/300\n",
            "938/938 [==============================] - 155s 165ms/step - loss: 4.7859e-04 - accuracy: 0.9999 - val_loss: 0.0323 - val_accuracy: 0.9937\n",
            "Epoch 98/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0314 - val_accuracy: 0.9942\n",
            "Epoch 99/300\n",
            "938/938 [==============================] - 146s 156ms/step - loss: 9.7811e-04 - accuracy: 0.9996 - val_loss: 0.0298 - val_accuracy: 0.9933\n",
            "Epoch 100/300\n",
            "938/938 [==============================] - 147s 157ms/step - loss: 6.2349e-04 - accuracy: 0.9998 - val_loss: 0.0267 - val_accuracy: 0.9951\n",
            "Epoch 101/300\n",
            "938/938 [==============================] - 146s 156ms/step - loss: 5.2757e-04 - accuracy: 0.9998 - val_loss: 0.0295 - val_accuracy: 0.9933\n",
            "Epoch 102/300\n",
            "938/938 [==============================] - 151s 161ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0311 - val_accuracy: 0.9940\n",
            "Epoch 103/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 8.9529e-04 - accuracy: 0.9998 - val_loss: 0.0305 - val_accuracy: 0.9941\n",
            "Epoch 104/300\n",
            "938/938 [==============================] - 151s 161ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0327 - val_accuracy: 0.9927\n",
            "Epoch 105/300\n",
            "938/938 [==============================] - 155s 166ms/step - loss: 9.8291e-04 - accuracy: 0.9997 - val_loss: 0.0288 - val_accuracy: 0.9940\n",
            "Epoch 106/300\n",
            "938/938 [==============================] - 147s 157ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0314 - val_accuracy: 0.9936\n",
            "Epoch 107/300\n",
            "938/938 [==============================] - 151s 161ms/step - loss: 9.1343e-04 - accuracy: 0.9997 - val_loss: 0.0280 - val_accuracy: 0.9942\n",
            "Epoch 108/300\n",
            "938/938 [==============================] - 145s 155ms/step - loss: 1.4912e-04 - accuracy: 0.9999 - val_loss: 0.0265 - val_accuracy: 0.9951\n",
            "Epoch 109/300\n",
            "938/938 [==============================] - 147s 157ms/step - loss: 8.9340e-04 - accuracy: 0.9998 - val_loss: 0.0356 - val_accuracy: 0.9930\n",
            "Epoch 110/300\n",
            "938/938 [==============================] - 151s 161ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0407 - val_accuracy: 0.9923\n",
            "Epoch 111/300\n",
            "938/938 [==============================] - 148s 158ms/step - loss: 4.9046e-04 - accuracy: 0.9999 - val_loss: 0.0325 - val_accuracy: 0.9941\n",
            "Epoch 112/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0342 - val_accuracy: 0.9923\n",
            "Epoch 113/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 5.5949e-04 - accuracy: 0.9999 - val_loss: 0.0328 - val_accuracy: 0.9942\n",
            "Epoch 114/300\n",
            "938/938 [==============================] - 151s 161ms/step - loss: 8.9111e-04 - accuracy: 0.9997 - val_loss: 0.0534 - val_accuracy: 0.9914\n",
            "Epoch 115/300\n",
            "938/938 [==============================] - 146s 156ms/step - loss: 3.3205e-04 - accuracy: 0.9999 - val_loss: 0.0281 - val_accuracy: 0.9941\n",
            "Epoch 116/300\n",
            "938/938 [==============================] - 147s 157ms/step - loss: 5.6226e-05 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9946\n",
            "Epoch 117/300\n",
            "938/938 [==============================] - 146s 155ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0386 - val_accuracy: 0.9930\n",
            "Epoch 118/300\n",
            "938/938 [==============================] - 146s 156ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0278 - val_accuracy: 0.9946\n",
            "Epoch 119/300\n",
            "938/938 [==============================] - 146s 155ms/step - loss: 2.0402e-04 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9935\n",
            "Epoch 120/300\n",
            "938/938 [==============================] - 149s 158ms/step - loss: 4.1198e-04 - accuracy: 0.9999 - val_loss: 0.0289 - val_accuracy: 0.9943\n",
            "Epoch 121/300\n",
            "938/938 [==============================] - 151s 160ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0303 - val_accuracy: 0.9940\n",
            "Epoch 122/300\n",
            "938/938 [==============================] - 151s 161ms/step - loss: 2.3016e-04 - accuracy: 0.9999 - val_loss: 0.0267 - val_accuracy: 0.9946\n",
            "Epoch 123/300\n",
            "938/938 [==============================] - 146s 155ms/step - loss: 1.3205e-04 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9945\n",
            "Epoch 124/300\n",
            "938/938 [==============================] - 148s 157ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0304 - val_accuracy: 0.9939\n",
            "Epoch 125/300\n",
            "938/938 [==============================] - 145s 155ms/step - loss: 9.9533e-05 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9946\n",
            "Epoch 126/300\n",
            "938/938 [==============================] - 152s 162ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0273 - val_accuracy: 0.9945\n",
            "Epoch 127/300\n",
            "938/938 [==============================] - 151s 161ms/step - loss: 7.4179e-05 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9949\n",
            "Epoch 128/300\n",
            "938/938 [==============================] - 146s 156ms/step - loss: 3.2291e-05 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9945\n",
            "Epoch 129/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0314 - val_accuracy: 0.9943\n",
            "Epoch 130/300\n",
            "938/938 [==============================] - 146s 155ms/step - loss: 6.5575e-04 - accuracy: 0.9998 - val_loss: 0.0284 - val_accuracy: 0.9944\n",
            "Epoch 131/300\n",
            "938/938 [==============================] - 147s 157ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0359 - val_accuracy: 0.9920\n",
            "Epoch 132/300\n",
            "938/938 [==============================] - 146s 155ms/step - loss: 3.1865e-04 - accuracy: 0.9999 - val_loss: 0.0253 - val_accuracy: 0.9940\n",
            "Epoch 133/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 3.4902e-04 - accuracy: 0.9999 - val_loss: 0.0376 - val_accuracy: 0.9927\n",
            "Epoch 134/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0268 - val_accuracy: 0.9953\n",
            "Epoch 135/300\n",
            "938/938 [==============================] - 145s 155ms/step - loss: 1.5233e-04 - accuracy: 0.9999 - val_loss: 0.0274 - val_accuracy: 0.9950\n",
            "Epoch 136/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 5.1807e-05 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9953\n",
            "Epoch 137/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 2.8650e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9949\n",
            "Epoch 138/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 1.1079e-05 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9948\n",
            "Epoch 139/300\n",
            "938/938 [==============================] - 145s 154ms/step - loss: 6.6672e-06 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9954\n",
            "Epoch 140/300\n",
            "938/938 [==============================] - 149s 159ms/step - loss: 4.6836e-06 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9950\n",
            "Epoch 141/300\n",
            "938/938 [==============================] - 145s 154ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0368 - val_accuracy: 0.9933\n",
            "Epoch 142/300\n",
            "938/938 [==============================] - 145s 154ms/step - loss: 8.6756e-04 - accuracy: 0.9997 - val_loss: 0.0422 - val_accuracy: 0.9923\n",
            "Epoch 143/300\n",
            "938/938 [==============================] - 144s 154ms/step - loss: 8.0565e-04 - accuracy: 0.9997 - val_loss: 0.0260 - val_accuracy: 0.9944\n",
            "Epoch 144/300\n",
            "938/938 [==============================] - 146s 155ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0306 - val_accuracy: 0.9941\n",
            "Epoch 145/300\n",
            "938/938 [==============================] - 144s 153ms/step - loss: 6.4559e-04 - accuracy: 0.9998 - val_loss: 0.0287 - val_accuracy: 0.9944\n",
            "Epoch 146/300\n",
            "938/938 [==============================] - 149s 159ms/step - loss: 7.0999e-04 - accuracy: 0.9998 - val_loss: 0.0285 - val_accuracy: 0.9948\n",
            "Epoch 147/300\n",
            "938/938 [==============================] - 149s 159ms/step - loss: 2.3864e-04 - accuracy: 0.9999 - val_loss: 0.0295 - val_accuracy: 0.9950\n",
            "Epoch 148/300\n",
            "938/938 [==============================] - 149s 159ms/step - loss: 4.8771e-04 - accuracy: 0.9998 - val_loss: 0.0328 - val_accuracy: 0.9939\n",
            "Epoch 149/300\n",
            "938/938 [==============================] - 145s 155ms/step - loss: 1.1290e-04 - accuracy: 0.9999 - val_loss: 0.0367 - val_accuracy: 0.9938\n",
            "Epoch 150/300\n",
            "938/938 [==============================] - 144s 153ms/step - loss: 8.5756e-04 - accuracy: 0.9997 - val_loss: 0.0718 - val_accuracy: 0.9889\n",
            "Epoch 151/300\n",
            "938/938 [==============================] - 150s 160ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0320 - val_accuracy: 0.9942\n",
            "Epoch 152/300\n",
            "938/938 [==============================] - ETA: 0s - loss: 4.9152e-04 - accuracy: 0.9998"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Residual block function\n",
        "def residual_block(x, filters, kernel_size=3, strides=1):\n",
        "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "    y = layers.Activation('relu')(y)\n",
        "\n",
        "    y = layers.Conv2D(filters, kernel_size=kernel_size, padding='same')(y)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "\n",
        "    if strides > 1:\n",
        "        x = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(x)\n",
        "\n",
        "    out = layers.Add()([x, y])\n",
        "    out = layers.Activation('relu')(out)\n",
        "    return out\n",
        "\n",
        "# Build ResNet-10 model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(64, (7, 7), strides=2, input_shape=(28, 28, 1), padding='same'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D((3, 3), strides=2, padding='same'))\n",
        "\n",
        "# Add 10 residual blocks\n",
        "x = model.output\n",
        "for _ in range(5):\n",
        "    x = residual_block(x, filters=64)\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, strides=1, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history = model.fit(train_images, train_labels, epochs=300, batch_size=64, validation_data=(test_images, test_labels))\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model.evaluate(test_images, test_labels)\n",
        "\n",
        "# Report the results\n",
        "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
        "print(f\"Training Loss after 300 epochs: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"Evaluation Accuracy after 300 epochs: {evaluation[1] * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ag8D1CtgJfj"
      },
      "source": [
        "### Weight Decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3HlZkAGdNu2",
        "outputId": "8851fda5-93ec-4695-c8a3-eae398571a7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_66 (Conv2D)          (None, 14, 14, 64)        3200      \n",
            "                                                                 \n",
            " batch_normalization_61 (Bat  (None, 14, 14, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_61 (Activation)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 64)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,106\n",
            "Trainable params: 3,978\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 1.4144 - accuracy: 0.6114 - val_loss: 1.1334 - val_accuracy: 0.6685\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.1334 - accuracy: 0.6685\n",
            "\n",
            "Weight Decay:\n",
            "Training Time: 41.20 seconds\n",
            "Training Loss after 300 epochs: 1.4144\n",
            "Evaluation Accuracy after 300 epochs: 66.85%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers\n",
        "import time\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Residual block function with weight decay\n",
        "def residual_block_weight_decay(x, filters, kernel_size=3, strides=1, weight_decay=0.001):\n",
        "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "    y = layers.Activation('relu')(y)\n",
        "\n",
        "    y = layers.Conv2D(filters, kernel_size=kernel_size, padding='same', kernel_regularizer=regularizers.l2(weight_decay))(y)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "\n",
        "    if strides > 1:\n",
        "        x = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
        "\n",
        "    out = layers.Add()([x, y])\n",
        "    out = layers.Activation('relu')(out)\n",
        "    return out\n",
        "\n",
        "# Build ResNet-10 model with weight decay\n",
        "model_weight_decay = models.Sequential()\n",
        "model_weight_decay.add(layers.Conv2D(64, (7, 7), strides=2, input_shape=(28, 28, 1), padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model_weight_decay.add(layers.BatchNormalization())\n",
        "model_weight_decay.add(layers.Activation('relu'))\n",
        "model_weight_decay.add(layers.MaxPooling2D((3, 3), strides=2, padding='same'))\n",
        "\n",
        "# Add 10 residual blocks with weight decay\n",
        "x = model_weight_decay.output\n",
        "for _ in range(5):\n",
        "    x = residual_block_weight_decay(x, filters=64, weight_decay=0.001)\n",
        "\n",
        "model_weight_decay.add(layers.GlobalAveragePooling2D())\n",
        "model_weight_decay.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_weight_decay.compile(optimizer='adam',\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model_weight_decay.summary()\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history_weight_decay = model_weight_decay.fit(train_images, train_labels, epochs=1, batch_size=64, validation_data=(test_images, test_labels))\n",
        "training_time_weight_decay = time.time() - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation_weight_decay = model_weight_decay.evaluate(test_images, test_labels)\n",
        "\n",
        "# Report the results\n",
        "print(\"\\nWeight Decay:\")\n",
        "print(f\"Training Time: {training_time_weight_decay:.2f} seconds\")\n",
        "print(f\"Training Loss after 300 epochs: {history_weight_decay.history['loss'][-1]:.4f}\")\n",
        "print(f\"Evaluation Accuracy after 300 epochs: {evaluation_weight_decay[1] * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xchEjHniaDp"
      },
      "source": [
        "### Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-FPcQufgMaf",
        "outputId": "1d194870-2419-4571-e897-42cceb46a16f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_97 (Conv2D)          (None, 14, 14, 64)        3200      \n",
            "                                                                 \n",
            " batch_normalization_101 (Ba  (None, 14, 14, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_92 (Activation)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d_5   (None, 64)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,106\n",
            "Trainable params: 3,978\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "938/938 [==============================] - 48s 50ms/step - loss: 1.4244 - accuracy: 0.6015 - val_loss: 1.1053 - val_accuracy: 0.7024\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.1053 - accuracy: 0.7024\n",
            "\n",
            "Batch Normalization:\n",
            "Training Time: 48.62 seconds\n",
            "Training Loss after 300 epochs: 1.4244\n",
            "Evaluation Accuracy after 300 epochs: 70.24%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Residual block function with batch normalization\n",
        "def residual_block_batch_norm(x, filters, kernel_size=3, strides=1):\n",
        "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "    y = layers.Activation('relu')(y)\n",
        "\n",
        "    y = layers.Conv2D(filters, kernel_size=kernel_size, padding='same')(y)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "\n",
        "    if strides > 1:\n",
        "        x = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(x)\n",
        "\n",
        "    out = layers.Add()([x, y])\n",
        "    out = layers.Activation('relu')(out)\n",
        "    out = layers.BatchNormalization()(out)\n",
        "    return out\n",
        "\n",
        "# Build ResNet-10 model with batch normalization\n",
        "model_batch_norm = models.Sequential()\n",
        "model_batch_norm.add(layers.Conv2D(64, (7, 7), strides=2, input_shape=(28, 28, 1), padding='same'))\n",
        "model_batch_norm.add(layers.BatchNormalization())\n",
        "model_batch_norm.add(layers.Activation('relu'))\n",
        "model_batch_norm.add(layers.MaxPooling2D((3, 3), strides=2, padding='same'))\n",
        "\n",
        "# Add 10 residual blocks with batch normalization\n",
        "x = model_batch_norm.output\n",
        "for _ in range(5):\n",
        "    x = residual_block_batch_norm(x, filters=64)\n",
        "\n",
        "model_batch_norm.add(layers.GlobalAveragePooling2D())\n",
        "model_batch_norm.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_batch_norm.compile(optimizer='adam',\n",
        "                        loss='categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model_batch_norm.summary()\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history_batch_norm = model_batch_norm.fit(train_images, train_labels, epochs=1, batch_size=64, validation_data=(test_images, test_labels))\n",
        "training_time_batch_norm = time.time() - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation_batch_norm = model_batch_norm.evaluate(test_images, test_labels)\n",
        "\n",
        "# Report the results\n",
        "print(\"\\nBatch Normalization:\")\n",
        "print(f\"Training Time: {training_time_batch_norm:.2f} seconds\")\n",
        "print(f\"Training Loss after 300 epochs: {history_batch_norm.history['loss'][-1]:.4f}\")\n",
        "print(f\"Evaluation Accuracy after 300 epochs: {evaluation_batch_norm[1] * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIIlskmcXTZ5"
      },
      "source": [
        "### Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgsvDwaXfBSR"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Keep only the samples corresponding to classes 0 to 4\n",
        "train_mask = (y_train <= 4)\n",
        "test_mask = (y_test <= 4)\n",
        "\n",
        "x_train, y_train = x_train[train_mask], y_train[train_mask]\n",
        "x_test, y_test = x_test[test_mask], y_test[test_mask]\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Expand dimensions to add a channel dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=5)\n",
        "y_test = to_categorical(y_test, num_classes=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNvrM7HAhCEI",
        "outputId": "6e0918c0-8f7e-4ffc-c367-533b99bcab60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_44 (Conv2D)          (None, 14, 14, 64)        3200      \n",
            "                                                                 \n",
            " batch_normalization_44 (Bat  (None, 14, 14, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_44 (Activation)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d_4   (None, 64)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,106\n",
            "Trainable params: 3,978\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "938/938 [==============================] - 46s 48ms/step - loss: 1.4428 - accuracy: 0.6005 - val_loss: 1.1409 - val_accuracy: 0.6098\n",
            "Epoch 2/300\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 1.0031 - accuracy: 0.7330 - val_loss: 0.9274 - val_accuracy: 0.7252\n",
            "Epoch 3/300\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.8219 - accuracy: 0.7868 - val_loss: 0.8052 - val_accuracy: 0.7615\n",
            "Epoch 4/300\n",
            "938/938 [==============================] - 43s 45ms/step - loss: 0.7093 - accuracy: 0.8178 - val_loss: 0.7241 - val_accuracy: 0.7850\n",
            "Epoch 5/300\n",
            "938/938 [==============================] - 42s 44ms/step - loss: 0.6282 - accuracy: 0.8387 - val_loss: 0.7174 - val_accuracy: 0.7740\n",
            "Epoch 6/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.5708 - accuracy: 0.8522 - val_loss: 0.5403 - val_accuracy: 0.8509\n",
            "Epoch 7/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.5244 - accuracy: 0.8633 - val_loss: 0.5765 - val_accuracy: 0.8420\n",
            "Epoch 8/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.4870 - accuracy: 0.8729 - val_loss: 0.4965 - val_accuracy: 0.8592\n",
            "Epoch 9/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.4554 - accuracy: 0.8809 - val_loss: 0.4385 - val_accuracy: 0.8888\n",
            "Epoch 10/300\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.4313 - accuracy: 0.8864 - val_loss: 0.5779 - val_accuracy: 0.8059\n",
            "Epoch 11/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.4073 - accuracy: 0.8935 - val_loss: 0.4260 - val_accuracy: 0.8815\n",
            "Epoch 12/300\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.3884 - accuracy: 0.8969 - val_loss: 0.3765 - val_accuracy: 0.8973\n",
            "Epoch 13/300\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.3724 - accuracy: 0.9017 - val_loss: 0.3708 - val_accuracy: 0.8966\n",
            "Epoch 14/300\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.3547 - accuracy: 0.9066 - val_loss: 0.4141 - val_accuracy: 0.8776\n",
            "Epoch 15/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.3419 - accuracy: 0.9089 - val_loss: 0.4924 - val_accuracy: 0.8476\n",
            "Epoch 16/300\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.3309 - accuracy: 0.9100 - val_loss: 0.3475 - val_accuracy: 0.9028\n",
            "Epoch 17/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.3218 - accuracy: 0.9127 - val_loss: 0.3860 - val_accuracy: 0.8849\n",
            "Epoch 18/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.3106 - accuracy: 0.9168 - val_loss: 0.3701 - val_accuracy: 0.8923\n",
            "Epoch 19/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.3036 - accuracy: 0.9180 - val_loss: 0.3200 - val_accuracy: 0.9095\n",
            "Epoch 20/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.2940 - accuracy: 0.9200 - val_loss: 0.2744 - val_accuracy: 0.9239\n",
            "Epoch 21/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.2876 - accuracy: 0.9221 - val_loss: 0.2886 - val_accuracy: 0.9193\n",
            "Epoch 22/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.2781 - accuracy: 0.9240 - val_loss: 0.3030 - val_accuracy: 0.9122\n",
            "Epoch 23/300\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.2741 - accuracy: 0.9250 - val_loss: 0.2896 - val_accuracy: 0.9140\n",
            "Epoch 24/300\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.2662 - accuracy: 0.9268 - val_loss: 0.2900 - val_accuracy: 0.9130\n",
            "Epoch 25/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.2597 - accuracy: 0.9295 - val_loss: 0.2819 - val_accuracy: 0.9171\n",
            "Epoch 26/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.2555 - accuracy: 0.9295 - val_loss: 0.2473 - val_accuracy: 0.9306\n",
            "Epoch 27/300\n",
            "938/938 [==============================] - 42s 44ms/step - loss: 0.2510 - accuracy: 0.9311 - val_loss: 0.2520 - val_accuracy: 0.9275\n",
            "Epoch 28/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.2467 - accuracy: 0.9325 - val_loss: 0.2452 - val_accuracy: 0.9278\n",
            "Epoch 29/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.2429 - accuracy: 0.9327 - val_loss: 0.3576 - val_accuracy: 0.8859\n",
            "Epoch 30/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.2379 - accuracy: 0.9347 - val_loss: 0.2682 - val_accuracy: 0.9217\n",
            "Epoch 31/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.2352 - accuracy: 0.9347 - val_loss: 0.2994 - val_accuracy: 0.9086\n",
            "Epoch 32/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.2306 - accuracy: 0.9353 - val_loss: 0.2567 - val_accuracy: 0.9246\n",
            "Epoch 33/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.2269 - accuracy: 0.9367 - val_loss: 0.3283 - val_accuracy: 0.8971\n",
            "Epoch 34/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.2236 - accuracy: 0.9373 - val_loss: 0.2291 - val_accuracy: 0.9317\n",
            "Epoch 35/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.2189 - accuracy: 0.9384 - val_loss: 0.2480 - val_accuracy: 0.9239\n",
            "Epoch 36/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.2172 - accuracy: 0.9383 - val_loss: 0.2704 - val_accuracy: 0.9178\n",
            "Epoch 37/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.2142 - accuracy: 0.9398 - val_loss: 0.2600 - val_accuracy: 0.9217\n",
            "Epoch 38/300\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.2100 - accuracy: 0.9418 - val_loss: 0.2776 - val_accuracy: 0.9137\n",
            "Epoch 39/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.2083 - accuracy: 0.9419 - val_loss: 0.2418 - val_accuracy: 0.9250\n",
            "Epoch 40/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.2066 - accuracy: 0.9418 - val_loss: 0.2142 - val_accuracy: 0.9387\n",
            "Epoch 41/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.2027 - accuracy: 0.9431 - val_loss: 0.3350 - val_accuracy: 0.8949\n",
            "Epoch 42/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.2019 - accuracy: 0.9425 - val_loss: 0.2200 - val_accuracy: 0.9348\n",
            "Epoch 43/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.1984 - accuracy: 0.9438 - val_loss: 0.2146 - val_accuracy: 0.9354\n",
            "Epoch 44/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.1964 - accuracy: 0.9441 - val_loss: 0.2240 - val_accuracy: 0.9309\n",
            "Epoch 45/300\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.1950 - accuracy: 0.9444 - val_loss: 0.2269 - val_accuracy: 0.9317\n",
            "Epoch 46/300\n",
            "938/938 [==============================] - 39s 42ms/step - loss: 0.1912 - accuracy: 0.9459 - val_loss: 0.2441 - val_accuracy: 0.9235\n",
            "Epoch 47/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.1891 - accuracy: 0.9461 - val_loss: 0.2407 - val_accuracy: 0.9249\n",
            "Epoch 48/300\n",
            "938/938 [==============================] - 42s 44ms/step - loss: 0.1870 - accuracy: 0.9468 - val_loss: 0.2598 - val_accuracy: 0.9184\n",
            "Epoch 49/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.1864 - accuracy: 0.9463 - val_loss: 0.2412 - val_accuracy: 0.9259\n",
            "Epoch 50/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.1854 - accuracy: 0.9468 - val_loss: 0.2161 - val_accuracy: 0.9367\n",
            "Epoch 51/300\n",
            "938/938 [==============================] - 42s 44ms/step - loss: 0.1825 - accuracy: 0.9479 - val_loss: 0.1937 - val_accuracy: 0.9419\n",
            "Epoch 52/300\n",
            "938/938 [==============================] - 42s 44ms/step - loss: 0.1803 - accuracy: 0.9480 - val_loss: 0.2145 - val_accuracy: 0.9357\n",
            "Epoch 53/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.1806 - accuracy: 0.9483 - val_loss: 0.2096 - val_accuracy: 0.9352\n",
            "Epoch 54/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.1782 - accuracy: 0.9487 - val_loss: 0.1911 - val_accuracy: 0.9430\n",
            "Epoch 55/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.1759 - accuracy: 0.9493 - val_loss: 0.2102 - val_accuracy: 0.9343\n",
            "Epoch 56/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.1751 - accuracy: 0.9495 - val_loss: 0.2491 - val_accuracy: 0.9237\n",
            "Epoch 57/300\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.1736 - accuracy: 0.9488 - val_loss: 0.1999 - val_accuracy: 0.9391\n",
            "Epoch 58/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.1719 - accuracy: 0.9501 - val_loss: 0.1884 - val_accuracy: 0.9437\n",
            "Epoch 59/300\n",
            "938/938 [==============================] - 40s 42ms/step - loss: 0.1709 - accuracy: 0.9506 - val_loss: 0.2036 - val_accuracy: 0.9384\n",
            "Epoch 60/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.1701 - accuracy: 0.9503 - val_loss: 0.1922 - val_accuracy: 0.9417\n",
            "Epoch 61/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.1685 - accuracy: 0.9507 - val_loss: 0.2279 - val_accuracy: 0.9279\n",
            "Epoch 62/300\n",
            "938/938 [==============================] - 42s 44ms/step - loss: 0.1667 - accuracy: 0.9517 - val_loss: 0.2072 - val_accuracy: 0.9364\n",
            "Epoch 63/300\n",
            "938/938 [==============================] - 42s 44ms/step - loss: 0.1648 - accuracy: 0.9523 - val_loss: 0.1899 - val_accuracy: 0.9422\n",
            "Epoch 64/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.1630 - accuracy: 0.9528 - val_loss: 0.2005 - val_accuracy: 0.9406\n",
            "Epoch 65/300\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.1633 - accuracy: 0.9527 - val_loss: 0.1773 - val_accuracy: 0.9463\n",
            "Epoch 66/300\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.1622 - accuracy: 0.9536 - val_loss: 0.1933 - val_accuracy: 0.9424\n",
            "Epoch 67/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.1606 - accuracy: 0.9535 - val_loss: 0.1981 - val_accuracy: 0.9389\n",
            "Epoch 68/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.1596 - accuracy: 0.9533 - val_loss: 0.2242 - val_accuracy: 0.9276\n",
            "Epoch 69/300\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.1582 - accuracy: 0.9541 - val_loss: 0.2138 - val_accuracy: 0.9316\n",
            "Epoch 70/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.1595 - accuracy: 0.9535 - val_loss: 0.2051 - val_accuracy: 0.9374\n",
            "Epoch 71/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.1580 - accuracy: 0.9545 - val_loss: 0.2224 - val_accuracy: 0.9295\n",
            "Epoch 72/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.1560 - accuracy: 0.9536 - val_loss: 0.1824 - val_accuracy: 0.9441\n",
            "Epoch 73/300\n",
            "938/938 [==============================] - 41s 44ms/step - loss: 0.1563 - accuracy: 0.9545 - val_loss: 0.2097 - val_accuracy: 0.9352\n",
            "Epoch 74/300\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.1548 - accuracy: 0.9540 - val_loss: 0.1993 - val_accuracy: 0.9387\n",
            "Epoch 75/300\n",
            "938/938 [==============================] - 39s 41ms/step - loss: 0.1519 - accuracy: 0.9559 - val_loss: 0.1689 - val_accuracy: 0.9482\n",
            "Epoch 76/300\n",
            "938/938 [==============================] - 39s 41ms/step - loss: 0.1537 - accuracy: 0.9544 - val_loss: 0.2026 - val_accuracy: 0.9355\n",
            "Epoch 77/300\n",
            "938/938 [==============================] - 39s 41ms/step - loss: 0.1516 - accuracy: 0.9555 - val_loss: 0.1972 - val_accuracy: 0.9369\n",
            "Epoch 78/300\n",
            "938/938 [==============================] - 39s 42ms/step - loss: 0.1531 - accuracy: 0.9552 - val_loss: 0.1664 - val_accuracy: 0.9510\n",
            "Epoch 79/300\n",
            "938/938 [==============================] - 39s 42ms/step - loss: 0.1495 - accuracy: 0.9569 - val_loss: 0.1836 - val_accuracy: 0.9439\n",
            "Epoch 80/300\n",
            "938/938 [==============================] - 40s 42ms/step - loss: 0.1487 - accuracy: 0.9569 - val_loss: 0.1979 - val_accuracy: 0.9362\n",
            "Epoch 81/300\n",
            "938/938 [==============================] - 39s 42ms/step - loss: 0.1490 - accuracy: 0.9570 - val_loss: 0.1810 - val_accuracy: 0.9452\n",
            "Epoch 82/300\n",
            "938/938 [==============================] - 38s 41ms/step - loss: 0.1471 - accuracy: 0.9563 - val_loss: 0.1783 - val_accuracy: 0.9462\n",
            "Epoch 83/300\n",
            "938/938 [==============================] - 38s 40ms/step - loss: 0.1470 - accuracy: 0.9560 - val_loss: 0.1908 - val_accuracy: 0.9405\n",
            "Epoch 84/300\n",
            "938/938 [==============================] - 38s 41ms/step - loss: 0.1461 - accuracy: 0.9577 - val_loss: 0.1688 - val_accuracy: 0.9478\n",
            "Epoch 85/300\n",
            "938/938 [==============================] - 38s 40ms/step - loss: 0.1466 - accuracy: 0.9567 - val_loss: 0.2059 - val_accuracy: 0.9353\n",
            "Epoch 86/300\n",
            "938/938 [==============================] - 37s 40ms/step - loss: 0.1430 - accuracy: 0.9578 - val_loss: 0.1989 - val_accuracy: 0.9386\n",
            "Epoch 87/300\n",
            "938/938 [==============================] - 38s 40ms/step - loss: 0.1442 - accuracy: 0.9568 - val_loss: 0.2065 - val_accuracy: 0.9382\n",
            "Epoch 88/300\n",
            "821/938 [=========================>....] - ETA: 4s - loss: 0.1415 - accuracy: 0.9585"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Residual block function with dropout\n",
        "def residual_block_dropout(x, filters, kernel_size=3, strides=1, dropout_rate=0.3):\n",
        "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "    y = layers.Activation('relu')(y)\n",
        "    y = layers.Dropout(dropout_rate)(y)\n",
        "\n",
        "    y = layers.Conv2D(filters, kernel_size=kernel_size, padding='same')(y)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "    y = layers.Dropout(dropout_rate)(y)\n",
        "\n",
        "    if strides > 1:\n",
        "        x = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(x)\n",
        "\n",
        "    out = layers.Add()([x, y])\n",
        "    out = layers.Activation('relu')(out)\n",
        "    return out\n",
        "\n",
        "# Build ResNet-10 model with dropout\n",
        "model_dropout = models.Sequential()\n",
        "model_dropout.add(layers.Conv2D(64, (7, 7), strides=2, input_shape=(28, 28, 1), padding='same'))\n",
        "model_dropout.add(layers.BatchNormalization())\n",
        "model_dropout.add(layers.Activation('relu'))\n",
        "model_dropout.add(layers.MaxPooling2D((3, 3), strides=2, padding='same'))\n",
        "\n",
        "# Add 10 residual blocks with dropout\n",
        "x = model_dropout.output\n",
        "for _ in range(5):\n",
        "    x = residual_block_dropout(x, filters=64, dropout_rate=0.3)\n",
        "\n",
        "model_dropout.add(layers.GlobalAveragePooling2D())\n",
        "model_dropout.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_dropout.compile(optimizer='adam',\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model_dropout.summary()\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history_dropout = model_dropout.fit(train_images, train_labels, epochs=300, batch_size=64, validation_data=(test_images, test_labels))\n",
        "training_time_dropout = time.time() - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation_dropout = model_dropout.evaluate(test_images, test_labels)\n",
        "\n",
        "# Report the results\n",
        "print(\"\\nDropout:\")\n",
        "print(f\"Training Time: {training_time_dropout:.2f} seconds\")\n",
        "print(f\"Training Loss after 300 epochs: {history_dropout.history['loss'][-1]:.4f}\")\n",
        "print(f\"Evaluation Accuracy after 300 epochs: {evaluation_dropout[1] * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRPwLmfuisrj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}